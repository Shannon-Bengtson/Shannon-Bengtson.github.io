{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-10T02:18:09.215577Z",
     "start_time": "2021-06-10T02:18:06.246033Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabling notebook extension jupyter-leaflet/extension...\r\n",
      "      - Validating: \u001b[32mOK\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pysmile\n",
    "import sys\n",
    "sys.path.append('/src/python_classes')\n",
    "import pysmile_license\n",
    "!jupyter nbextension enable --py --sys-prefix ipyleaflet\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "from ipyleaflet import *\n",
    "import ipywidgets as widgets\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import folium\n",
    "from colormap import rgb2hex\n",
    "from folium.plugins import FloatImage\n",
    "import pickle\n",
    "\n",
    "from BNModel import BNModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_file = open(\"Submodels/SM4_water_level/ocean_model.pkl\", \"rb\")\n",
    "ocean_model_dict = pickle.load(a_file)\n",
    "\n",
    "a_file = open(\"Submodels/SM4_water_level/lagoon_model.pkl\", \"rb\")\n",
    "lagoon_model_dict = pickle.load(a_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'variables': {'wind_u': {'label': 'Wind u vector (m/s)',\n",
       "   'discretisation': {'n_bins': 5,\n",
       "    'strategy': 'kmeans',\n",
       "    'bin_names': ['VeryLow', 'Low', 'Mid', 'High', 'VeryHigh']},\n",
       "   'child_nodes': ['TWL_less_Tide'],\n",
       "   'training_data_preprocessed': {0: array([-4.2719574 , -4.07846069, -5.93629456, ..., -8.30755615,\n",
       "            1.69932556, -0.80697632])},\n",
       "   'testing_data_preprocessed': {0: array([-4.42945862, -6.86306763, -3.78572083, ...,  7.75259399,\n",
       "           -2.20835876, -3.63598633])},\n",
       "   'training_data': {0: array(['Low', 'Low', 'VeryLow', ..., 'VeryLow', 'High', 'High'],\n",
       "          dtype='<U21')},\n",
       "   'testing_data': {0: array(['Low', 'VeryLow', 'Low', ..., 'VeryHigh', 'Mid', 'Low'],\n",
       "          dtype='<U32')},\n",
       "   'bin_edges': {0: array([-12.8588562 ,  -5.72643208,  -3.45901471,  -0.82166763,\n",
       "             2.71004547,  12.9216156 ])},\n",
       "   'id': 0,\n",
       "   'evidence': [0, 0, 1, 0, 0],\n",
       "   'resulting_probs': {0: {'VeryLow': 0.0,\n",
       "     'Low': 0.0,\n",
       "     'Mid': 1.0,\n",
       "     'High': 0.0,\n",
       "     'VeryHigh': 0.0}},\n",
       "   'figure': 'wind_u_key590_graph.jpeg'},\n",
       "  'wind_v': {'label': 'Wind v vector (m/s)',\n",
       "   'discretisation': {'n_bins': 5,\n",
       "    'strategy': 'uniform',\n",
       "    'bin_names': ['VeryLow', 'Low', 'Mid', 'High', 'VeryHigh']},\n",
       "   'child_nodes': ['TWL_less_Tide'],\n",
       "   'training_data_preprocessed': {0: array([ 1.64927673, -0.52931213, -1.35836792, ..., -0.61943054,\n",
       "            1.77796936,  1.6942749 ])},\n",
       "   'testing_data_preprocessed': {0: array([-1.82344055,  0.83787537, -3.9083252 , ..., -1.51042175,\n",
       "           -0.89985657,  1.63108826])},\n",
       "   'training_data': {0: array(['High', 'Mid', 'Mid', ..., 'Mid', 'High', 'High'], dtype='<U21')},\n",
       "   'testing_data': {0: array(['Mid', 'High', 'Mid', ..., 'Mid', 'Mid', 'High'], dtype='<U32')},\n",
       "   'bin_edges': {0: array([-13.95506287,  -9.30842285,  -4.66178284,  -0.01514282,\n",
       "             4.63149719,   9.27813721])},\n",
       "   'id': 1,\n",
       "   'evidence': [0, 0, 1, 0, 0],\n",
       "   'resulting_probs': {0: {'VeryLow': 0.0,\n",
       "     'Low': 0.0,\n",
       "     'Mid': 1.0,\n",
       "     'High': 0.0,\n",
       "     'VeryHigh': 0.0}},\n",
       "   'figure': 'wind_v_key265_graph.jpeg'},\n",
       "  'Hs_offshore': {'label': 'Offshore wave height (m)',\n",
       "   'discretisation': {'n_bins': 5,\n",
       "    'strategy': 'kmeans',\n",
       "    'bin_names': ['VeryLow', 'Low', 'Mid', 'HighMid', 'VeryHigh']},\n",
       "   'child_nodes': ['TWL_less_Tide'],\n",
       "   'training_data_preprocessed': {0: array([0.58984923, 0.58697122, 0.65969718, ..., 0.33179325, 0.22203816,\n",
       "           0.11187831])},\n",
       "   'testing_data_preprocessed': {0: array([0.5151912 , 0.70900327, 0.55270666, ..., 0.81924862, 0.11139581,\n",
       "           0.31179753])},\n",
       "   'training_data': {0: array(['VeryLow', 'VeryLow', 'VeryLow', ..., 'VeryLow', 'VeryLow',\n",
       "           'VeryLow'], dtype='<U21')},\n",
       "   'testing_data': {0: array(['VeryLow', 'VeryLow', 'VeryLow', ..., 'Low', 'VeryLow', 'VeryLow'],\n",
       "          dtype='<U32')},\n",
       "   'bin_edges': {0: array([0.03075462, 0.74166313, 1.09425769, 1.44691586, 1.85520567,\n",
       "           3.25219226])},\n",
       "   'id': 2,\n",
       "   'resulting_probs': {0: {'VeryLow': 0.0,\n",
       "     'Low': 0.0,\n",
       "     'Mid': 1.0,\n",
       "     'HighMid': 0.0,\n",
       "     'VeryHigh': 0.0}},\n",
       "   'figure': 'Hs_offshore_key675_graph.jpeg',\n",
       "   'evidence': [0, 0, 1, 0, 0]},\n",
       "  'Tm_offshore': {'label': 'Offshore wave period (s)',\n",
       "   'discretisation': {'n_bins': 5,\n",
       "    'strategy': 'kmeans',\n",
       "    'bin_names': ['VeryLow', 'Low', 'Mid', 'High', 'VeryHigh']},\n",
       "   'child_nodes': ['TWL_less_Tide'],\n",
       "   'training_data_preprocessed': {0: array([2.24771094, 2.10710168, 2.25310278, ..., 1.38339281, 1.42737424,\n",
       "           1.43052232])},\n",
       "   'testing_data_preprocessed': {0: array([1.93424463, 2.14044285, 1.93319464, ..., 2.61684513, 1.13754916,\n",
       "           1.81281364])},\n",
       "   'training_data': {0: array(['VeryLow', 'VeryLow', 'VeryLow', ..., 'VeryLow', 'VeryLow',\n",
       "           'VeryLow'], dtype='<U21')},\n",
       "   'testing_data': {0: array(['VeryLow', 'VeryLow', 'VeryLow', ..., 'VeryLow', 'VeryLow',\n",
       "           'VeryLow'], dtype='<U32')},\n",
       "   'bin_edges': {0: array([ 0.58909905,  3.21509653,  4.63600212,  6.10196587,  7.59458407,\n",
       "           13.27282715])},\n",
       "   'id': 3,\n",
       "   'resulting_probs': {0: {'VeryLow': 0.0,\n",
       "     'Low': 0.0,\n",
       "     'Mid': 1.0,\n",
       "     'High': 0.0,\n",
       "     'VeryHigh': 0.0}},\n",
       "   'figure': 'Tm_offshore_key851_graph.jpeg',\n",
       "   'evidence': [0, 0, 1, 0, 0]},\n",
       "  'Dir_offshore': {'label': 'Offshore wave direction (deg)',\n",
       "   'discretisation': {'n_bins': 8,\n",
       "    'strategy': 'kmeans',\n",
       "    'bin_names': ['NNE', 'ENE', 'ESE', 'SSE', 'SSW', 'WSW', 'WNW', 'NNW']},\n",
       "   'child_nodes': ['TWL_less_Tide'],\n",
       "   'training_data_preprocessed': {0: array([269.32165527, 271.44070435, 336.24118042, ..., 114.77561951,\n",
       "           265.81558228, 264.82052612])},\n",
       "   'testing_data_preprocessed': {0: array([229.04701233,  49.26675415, 354.42822266, ..., 267.91928101,\n",
       "           239.54380798, 247.20317078])},\n",
       "   'training_data': {0: array(['WNW', 'WNW', 'NNW', ..., 'ESE', 'WNW', 'WNW'], dtype='<U21')},\n",
       "   'testing_data': {0: array(['WNW', 'NNE', 'NNW', ..., 'WNW', 'WNW', 'WNW'], dtype='<U32')},\n",
       "   'bin_edges': {0: array([1.08032227e-02, 6.26663249e+01, 9.59642631e+01, 1.27884840e+02,\n",
       "           1.49668991e+02, 1.75581871e+02, 2.13285283e+02, 2.77894538e+02,\n",
       "           3.59994659e+02])},\n",
       "   'id': 4,\n",
       "   'resulting_probs': {0: {'NNE': 1.0,\n",
       "     'ENE': 0.0,\n",
       "     'ESE': 0.0,\n",
       "     'SSE': 0.0,\n",
       "     'SSW': 0.0,\n",
       "     'WSW': 0.0,\n",
       "     'WNW': 0.0,\n",
       "     'NNW': 0.0}},\n",
       "   'figure': 'Dir_offshore_key9_graph.jpeg',\n",
       "   'evidence': [1, 0, 0, 0, 0, 0, 0, 0]},\n",
       "  'TWL': {'label': 'Total water level (m)',\n",
       "   'discretisation': {'n_bins': 7,\n",
       "    'strategy': 'binned',\n",
       "    'bin_names': ['VeryLow',\n",
       "     'Low',\n",
       "     'LowMid',\n",
       "     'Mid',\n",
       "     'MidHigh',\n",
       "     'High',\n",
       "     'VeryHigh'],\n",
       "    'bin_edges': array([-1. , -0.5,  0. ,  0.5,  1. ,  1.5,  2. ,  2.5])},\n",
       "   'child_nodes': [],\n",
       "   'training_data_preprocessed': {0: array([ 0.13388943, -0.25108878,  0.32587618, ...,  1.64690403,\n",
       "            0.00376423,  0.73397493])},\n",
       "   'testing_data_preprocessed': {0: array([0.50285787, 0.34500247, 0.42000305, ..., 0.90659645, 0.34275232,\n",
       "           0.70960505])},\n",
       "   'training_data': {0: array(['LowMid', 'Low', 'LowMid', ..., 'High', 'LowMid', 'Mid'],\n",
       "          dtype='<U32')},\n",
       "   'testing_data': {0: array(['Mid', 'LowMid', 'LowMid', ..., 'Mid', 'LowMid', 'Mid'],\n",
       "          dtype='<U32')},\n",
       "   'bin_edges': {0: array([-1. , -0.5,  0. ,  0.5,  1. ,  1.5,  2. ,  2.5])},\n",
       "   'id': 5,\n",
       "   'resulting_probs': {0: {'VeryLow': 0.0,\n",
       "     'Low': 0.24119854418436742,\n",
       "     'LowMid': 0.7390692500369153,\n",
       "     'Mid': 0.01973220577871741,\n",
       "     'MidHigh': 0.0,\n",
       "     'High': 0.0,\n",
       "     'VeryHigh': 0.0}},\n",
       "   'figure': 'TWL_key351_graph.jpeg'},\n",
       "  'TWL_less_Tide': {'label': 'Total water level less tide (m)',\n",
       "   'discretisation': {'n_bins': 5,\n",
       "    'strategy': 'kmeans',\n",
       "    'bin_names': ['VeryLow', 'Low', 'Mid', 'High', 'VeryHigh']},\n",
       "   'child_nodes': ['TWL'],\n",
       "   'training_data_preprocessed': {0: array([-0.01897576, -0.01154886, -0.02833342, ..., -1.09216468,\n",
       "           -0.4647843 , -0.28661043])},\n",
       "   'testing_data_preprocessed': {0: array([-0.07841992, -0.05473879,  0.0621224 , ..., -0.5244665 ,\n",
       "           -0.49495035, -0.42480273])},\n",
       "   'training_data': {0: array(['High', 'High', 'High', ..., 'VeryLow', 'Low', 'Low'], dtype='<U21')},\n",
       "   'testing_data': {0: array(['Mid', 'Mid', 'VeryHigh', ..., 'VeryLow', 'Low', 'Low'],\n",
       "          dtype='<U32')},\n",
       "   'bin_edges': {0: array([-1.47095308, -0.49969568, -0.2225689 , -0.04492649,  0.03799821,\n",
       "            0.2303994 ])},\n",
       "   'id': 6,\n",
       "   'resulting_probs': {0: {'VeryLow': 0.0,\n",
       "     'Low': 0.09090909090909091,\n",
       "     'Mid': 0.4393939393939394,\n",
       "     'High': 0.46969696969696967,\n",
       "     'VeryHigh': 0.0}},\n",
       "   'figure': 'TWL_less_Tide_key341_graph.jpeg'},\n",
       "  'MSL': {'label': 'Mean sea level (m)',\n",
       "   'discretisation': {'n_bins': 5,\n",
       "    'strategy': 'kmeans',\n",
       "    'bin_names': ['VeryLow', 'Low', 'Mid', 'High', 'VeryHigh']},\n",
       "   'child_nodes': ['TWL_less_Tide'],\n",
       "   'training_data_preprocessed': {0: array([ 0.01361819,  0.00508482,  0.00743002, ..., -0.04280496,\n",
       "            0.08706445, -0.07613871])},\n",
       "   'testing_data_preprocessed': {0: array([ 0.06814756,  0.05227469, -0.0711696 , ...,  0.1133498 ,\n",
       "            0.03246683,  0.06088732])},\n",
       "   'training_data': {0: array(['Mid', 'Mid', 'Mid', ..., 'Low', 'VeryHigh', 'Low'], dtype='<U21')},\n",
       "   'testing_data': {0: array(['High', 'High', 'Low', ..., 'VeryHigh', 'High', 'High'],\n",
       "          dtype='<U32')},\n",
       "   'bin_edges': {0: array([-0.22734857, -0.09361827, -0.02824495,  0.01992245,  0.07488122,\n",
       "            0.20758728])},\n",
       "   'id': 7,\n",
       "   'resulting_probs': {0: {'VeryLow': 0.0,\n",
       "     'Low': 0.0,\n",
       "     'Mid': 0.0,\n",
       "     'High': 1.0,\n",
       "     'VeryHigh': 0.0}},\n",
       "   'figure': 'MSL_key82_graph.jpeg',\n",
       "   'evidence': [0, 0, 0, 1, 0]},\n",
       "  'Tide': {'label': 'Tide (m)',\n",
       "   'discretisation': {'n_bins': 5,\n",
       "    'strategy': 'kmeans',\n",
       "    'bin_names': ['VeryLow', 'Low', 'Mid', 'High', 'VeryHigh']},\n",
       "   'child_nodes': ['TWL'],\n",
       "   'training_data_preprocessed': {0: array([ 0.11491368, -0.26263764,  0.29754276, ...,  0.55473935,\n",
       "           -0.46102007,  0.4473645 ])},\n",
       "   'testing_data_preprocessed': {0: array([ 0.42443795,  0.29026369,  0.48212545, ...,  0.38212995,\n",
       "           -0.15219803,  0.28480232])},\n",
       "   'training_data': {0: array(['Mid', 'Low', 'High', ..., 'High', 'Low', 'High'], dtype='<U21')},\n",
       "   'testing_data': {0: array(['High', 'High', 'High', ..., 'High', 'Low', 'High'], dtype='<U32')},\n",
       "   'bin_edges': {0: array([-1.12419258, -0.50684234, -0.13483874,  0.21325769,  0.57572563,\n",
       "            1.22757784])},\n",
       "   'id': 8,\n",
       "   'resulting_probs': {0: {'VeryLow': 0.0,\n",
       "     'Low': 0.0,\n",
       "     'Mid': 1.0,\n",
       "     'High': 0.0,\n",
       "     'VeryHigh': 0.0}},\n",
       "   'figure': 'Tide_key707_graph.jpeg',\n",
       "   'evidence': [0, 0, 1, 0, 0]}},\n",
       " 'training_frac': 0.8,\n",
       " 'bootstrap_reps': 1}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the reef and shoreline profile information\n",
    "df_ocean_profiles = pd.read_csv('/src/Dataset/D8_tarawa_inundation/Profiles_definition_outer_reef_xyxy_processed.txt')\n",
    "df_lagoon_profiles = pd.read_csv('/src/Dataset/D8_tarawa_inundation/Profiles_definition_inner_lagoon_xyxy.txt',delim_whitespace=True,header=None)\n",
    "df_lagoon_profiles.columns = ['reef_long','reef_lat','shore_long','shore_lat','reef_depth']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_locator(value,bin_edges):\n",
    "    '''\n",
    "    function used for determining the index of the appropriate bin for a numerical value.\n",
    "    '''\n",
    "    i=0\n",
    "    for edge_1,edge_2 in zip(bin_edges[:-1],bin_edges[1:]):\n",
    "        if (value>edge_1)&(value<=edge_2):\n",
    "            loc_bin = i\n",
    "        else:\n",
    "            i+=1\n",
    "            continue\n",
    "\n",
    "    if value<=bin_edges[0]:\n",
    "        loc_bin = 0\n",
    "\n",
    "    if value>=bin_edges[-1]:\n",
    "        loc_bin = len(bin_edges)-2\n",
    "\n",
    "    return(loc_bin)\n",
    "\n",
    "def model_location(model_dict,location_details,evidence_dict,variable_list):\n",
    "    \n",
    "    '''\n",
    "    function for adding the location information for one side model to the evidence dictionary\n",
    "    '''\n",
    "    \n",
    "    for variable in variable_list:\n",
    "\n",
    "        bin_edges = model_dict['variables'][variable]['bin_edges'][0]\n",
    "        value = location_details[variable]\n",
    "\n",
    "        var_bin = bin_locator(value,bin_edges)\n",
    "        \n",
    "        evidence_array = [0]*(len(bin_edges)-1)\n",
    "        evidence_array[var_bin] = 1\n",
    "        \n",
    "        evidence_dict.update({\n",
    "            variable:evidence_array\n",
    "        })\n",
    "\n",
    "    # Add evidence to model dict\n",
    "    model_location_dict = BNModel().add_evidence_to_dict(model_dict,evidence_dict)\n",
    "    \n",
    "    # Set evidence and get beliefs\n",
    "    model_location_dict = BNModel().update_evidence(model_location_dict)\n",
    "    \n",
    "    return(model_location_dict)\n",
    "\n",
    "def location_probabilities(evidence_dict,model_dict,variable_list,df_profiles):\n",
    "    '''\n",
    "    \n",
    "    Function for setting evidence and determing probabilties for twl at each point around the island based \n",
    "    on the reef characteristics at each location\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    location_probabilities_dict = {}\n",
    "#     figure_dict = {}\n",
    "    \n",
    "    for index,row in df_profiles.iterrows():\n",
    "\n",
    "        model_location_dict = model_location(model_dict,row,evidence_dict,variable_list)\n",
    "        location_probabilities = model_location_dict['variables']['TWL']['resulting_probs'][0]\n",
    "\n",
    "        df_location_probabilities = pd.DataFrame.from_dict(location_probabilities,orient='index')\n",
    "        \n",
    "        largest_cat = df_location_probabilities.idxmax()[0]\n",
    "\n",
    "        location_probabilities_dict.update({\n",
    "            (row.reef_long,row.reef_lat):\\\n",
    "                model_dict['variables']['TWL']['discretisation']['bin_names'].index(largest_cat)\n",
    "        })\n",
    "        \n",
    "#         figure_dict.update({\n",
    "#             (row.reef_long,row.reef_lat):fig#html_graph\n",
    "#         })\n",
    "        \n",
    "    return(location_probabilities_dict)\n",
    "\n",
    "def data2geojson(df):\n",
    "    features = []\n",
    "    insert_features = lambda X: features.append(\n",
    "            geojson.Feature(geometry=geojson.Point((X[\"long\"],\n",
    "                                                    X[\"lat\"])),\n",
    "                            properties=dict(name=X[\"most_likely_twl\"])))\n",
    "    df.apply(insert_features, axis=1)\n",
    "        \n",
    "    return(geojson.FeatureCollection(features))\n",
    "\n",
    "# Load SLR Projections\n",
    "data_location = \"/src/Dataset/D7_MSL_projections/\"\n",
    "file_name = \"distributions_dict\"\n",
    "with open(\"{}{}.json\".format(data_location,file_name), 'r') as fp:\n",
    "    SL_proj_dict = json.load(fp)\n",
    "    \n",
    "def SLR_proj_extractor(SL_proj_dict,AIS_config,rcp,year):\n",
    "    '''\n",
    "    Function for getting SLR projections for a given Antarctic icesheet, rcp and year\n",
    "    Years start as 2020 and go up in lots of 10 until 2150 (2100 for dp16)\n",
    "    '''\n",
    "    SLR_prob_dict = SL_proj_dict[\"('{}', '{}', {})\".format(AIS_config,rcp,year)]\n",
    "    SLR_median_prob = np.max([float(x) for x in list(SLR_prob_dict.keys())])\n",
    "    SLR_median_MSL = float(SLR_prob_dict[str(SLR_median_prob)])/1000 #units is m\n",
    "\n",
    "    return(SLR_median_MSL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ocean_model_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_41/2274866722.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;31m# compile the figure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;31m# lagoon_model_dict,ocean_model_dict = initialise_model_dictionaries()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m \u001b[0mtide_bins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mocean_model_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'variables'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Tide'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'discretisation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bin_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0mwave_height_bins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mocean_model_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'variables'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Hs_offshore'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'discretisation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bin_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0mwave_period_bin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mocean_model_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'variables'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Tm_offshore'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'discretisation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bin_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ocean_model_dict' is not defined"
     ]
    }
   ],
   "source": [
    "def figure(\n",
    "    view,tide_bin,wave_height_bin,wave_period_bin,wave_direction_bin,wind_u_bin,wind_v_bin,proj_time\n",
    "    ):\n",
    "    \n",
    "    ########### get the MSL bin based on slider value\n",
    "    msl_proj = SLR_proj_extractor(SL_proj_dict,'k14','26','{}'.format(proj_time))\n",
    "    ocean_model_dict['variables']['MSL']['bin_edges'][0]\n",
    "    bin_count = bin_locator(msl_proj,ocean_model_dict['variables']['MSL']['bin_edges'][0])\n",
    "    msl_bin = ocean_model_dict['variables']['MSL']['discretisation']['bin_names'][bin_count]\n",
    "    \n",
    "    if view == 'Map':\n",
    "        map_osm = folium.Map(location=[1.448888, 172.991794],zoom_start=11)\n",
    "    elif view == 'Satellite':\n",
    "        token = \"pk.eyJ1Ijoic2hhbm5vbi1iZW5ndHNvbiIsImEiOiJja3F1Y2Q0dHEwMzYwMm9wYmtzYzk2bDZuIn0.5jGMyEiJdmXs1HL7x3ThPw\" # your mapbox token\n",
    "        tileurl = 'https://api.mapbox.com/v4/mapbox.satellite/{z}/{x}/{y}@2x.png?access_token=' + str(token)\n",
    "\n",
    "        map_osm = folium.Map(location=[1.448888, 172.991794], zoom_start=11, tiles=tileurl, attr='Mapbox')\n",
    "        \n",
    "    twl_bin_edges = [round(x,2) for x in ocean_model_dict['variables']['TWL']['bin_edges'][0]]\n",
    "    twl_bins = ocean_model_dict['variables']['TWL']['discretisation']['bin_names']\n",
    "\n",
    "    colours_rgb = matplotlib.pyplot.get_cmap('seismic')(np.arange(0,1+1/len(twl_bins),1/(len(twl_bins)-1)))\n",
    "    colour_hex_dict = {i:rgb2hex(int(255*colours_rgb[i][0]),int(255*colours_rgb[i][1]),int(255*(colours_rgb[i][2]))) for i in np.arange(0,len(twl_bins),1)}\n",
    "    \n",
    "    ################################################\n",
    "    \n",
    "    # Create an empty dictionary for the evidence and populate as you go\n",
    "    ocean_evidence_dict = {}\n",
    "    \n",
    "    for var_bin,var_name in zip([tide_bin,msl_bin,wave_height_bin,wave_period_bin,wave_direction_bin],\n",
    "                                ['Tide','MSL','Hs_offshore','Tm_offshore','Dir_offshore']):\n",
    "\n",
    "        ## Set in the evidence dict to be as indicated in the dropdown\n",
    "        bin_index = ocean_model_dict['variables'][var_name]['discretisation']['bin_names'].index(var_bin)\n",
    "        # Create a list of the tide evidence (all zero except as indicated by dropdown. Dropdown=1)\n",
    "        evidence = [0 for x in ocean_model_dict['variables'][var_name]['discretisation']['bin_names']]\n",
    "        evidence[bin_index] = 1\n",
    "        ocean_evidence_dict.update({\n",
    "            var_name:evidence\n",
    "        })\n",
    "    \n",
    "    # Create a list of variables that are location specific to set as evidence in the network\n",
    "    variable_list = ['reef_width','reef_depth','forereef_slope','shore_dir']\n",
    "    \n",
    "    # get the probability dictionary\n",
    "    location_probabilities_dict = location_probabilities(ocean_evidence_dict,ocean_model_dict,variable_list,df_ocean_profiles)\n",
    "    \n",
    "    # Create dataframe to plot\n",
    "    df_twl_locations = pd.DataFrame.from_dict(location_probabilities_dict,orient='index').rename(columns={0:'most_likely_twl'})\n",
    "    df_twl_locations['long'] = [long for long,lat in df_twl_locations.index]\n",
    "    df_twl_locations['lat'] = [lat for long,lat in df_twl_locations.index]\n",
    "    df_twl_locations.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    data_ocean = data2geojson(df_twl_locations)\n",
    "    \n",
    "    colors_hex_points_ocean = [colour_hex_dict[x] for x in df_twl_locations.most_likely_twl]\n",
    "    \n",
    "    #####################################################################\n",
    "    \n",
    "    # Create an empty dictionary for the evidence and populate as you go\n",
    "    lagoon_evidence_dict = {}\n",
    "    \n",
    "    for var_bin,var_name in zip([tide_bin,msl_bin,wave_height_bin,wave_period_bin,wave_direction_bin,wind_u_bin,wind_v_bin],\n",
    "                                ['Tide','MSL','Hs_offshore','Tm_offshore','Dir_offshore','wind_u','wind_v']):\n",
    "\n",
    "        ## Set in the evidence dict to be as indicated in the dropdown\n",
    "        bin_index = lagoon_model_dict['variables'][var_name]['discretisation']['bin_names'].index(var_bin)\n",
    "        # Create a list of the tide evidence (all zero except as indicated by dropdown. Dropdown=1)\n",
    "        evidence = [0 for x in lagoon_model_dict['variables'][var_name]['discretisation']['bin_names']]\n",
    "        evidence[bin_index] = 1\n",
    "        lagoon_evidence_dict.update({\n",
    "            var_name:evidence\n",
    "        })\n",
    "    \n",
    "    # Create a list of variables that are location specific to set as evidence in the network\n",
    "    variable_list = []\n",
    "    \n",
    "    # get the probability dictionary\n",
    "    location_probabilities_dict = location_probabilities(lagoon_evidence_dict,lagoon_model_dict,variable_list,df_lagoon_profiles)\n",
    "    \n",
    "    # Create dataframe to plot\n",
    "    df_twl_locations = pd.DataFrame.from_dict(location_probabilities_dict,orient='index').rename(columns={0:'most_likely_twl'})\n",
    "    df_twl_locations['long'] = [long for long,lat in df_twl_locations.index]\n",
    "    df_twl_locations['lat'] = [lat for long,lat in df_twl_locations.index]\n",
    "    df_twl_locations.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    data_lagoon = data2geojson(df_twl_locations)\n",
    "    \n",
    "    colors_hex_points_lagoon = [colour_hex_dict[x] for x in df_twl_locations.most_likely_twl]\n",
    "    \n",
    "    #####################################################################\n",
    "    \n",
    "    features_list = data_ocean['features']+data_lagoon['features']\n",
    "    \n",
    "    data = data_ocean\n",
    "    data.update({\n",
    "        'features':features_list\n",
    "    })\n",
    "    \n",
    "    colors_hex_points = colors_hex_points_ocean+colors_hex_points_lagoon\n",
    "    \n",
    "    #####################################################################\n",
    "\n",
    "    for feature,color in zip(features_list,colors_hex_points):\n",
    "        feature['properties'] = {'color':color,'weight':1,'markerColor':color,'fillOpacity':1,'fillColor':color}\n",
    "        long,lat = feature['geometry']['coordinates']\n",
    "        \n",
    "        marker = folium.CircleMarker([lat,long],color=color,\n",
    "                                    # popup='<img src={}_{}.png>'.format(int(long*1000),int(lat*1000)),\n",
    "                                   fill_color=color,fill=True,fill_opacity='1',radius=5)\n",
    "        marker.add_to(map_osm)\n",
    "        \n",
    "    twl_bin_edge_labels = ['{} to {} m'.format(\n",
    "        x,y) for x,y in zip(twl_bin_edges[:-1],twl_bin_edges[1:])]\n",
    "        \n",
    "    output_list = []\n",
    "    for rgb_color in colours_rgb:\n",
    "        output = plt.scatter([],[],color=rgb_color)\n",
    "        output_list.append(output)\n",
    "        \n",
    "    legend = plt.legend(output_list,twl_bin_edge_labels,title='Total water level anomaly',fontsize=10)\n",
    "    plt.setp(legend.get_title(),fontsize=12)\n",
    "    \n",
    "    plt.axis('off')\n",
    "    plt.savefig('legend.png')\n",
    "    \n",
    "    plt.close()\n",
    "    \n",
    "    url = (\n",
    "        \"legend.png\"\n",
    "    )    \n",
    "    \n",
    "    FloatImage(url, bottom=55, left=55).add_to(map_osm)\n",
    "    \n",
    "    map_osm.save('test.html')\n",
    "        \n",
    "    return(map_osm)\n",
    "    \n",
    "\n",
    "# compile the figure\n",
    "# lagoon_model_dict,ocean_model_dict = initialise_model_dictionaries()\n",
    "tide_bins = ocean_model_dict['variables']['Tide']['discretisation']['bin_names']\n",
    "wave_height_bins = ocean_model_dict['variables']['Hs_offshore']['discretisation']['bin_names']\n",
    "wave_period_bin = ocean_model_dict['variables']['Tm_offshore']['discretisation']['bin_names']\n",
    "wave_direction_bin = ocean_model_dict['variables']['Dir_offshore']['discretisation']['bin_names']\n",
    "wind_u_bin = lagoon_model_dict['variables']['wind_u']['discretisation']['bin_names']\n",
    "wind_v_bin = lagoon_model_dict['variables']['wind_u']['discretisation']['bin_names']\n",
    "# time = list(model_dicts_through_time_dict.keys())  \n",
    "\n",
    "\n",
    "# Create the plot with the widget\n",
    "map_osm = interact(figure,\n",
    "                view = widgets.Dropdown(options=['Map','Satellite'],value='Map',description='View type',disabled=False),\n",
    "                tide_bin = widgets.Dropdown(options=tide_bins,value='Mid',description='Tide',disabled=False),\n",
    "                wave_height_bin = widgets.Dropdown(options=wave_height_bins,value='Mid',description='Wave height',disabled=False),\n",
    "                wave_period_bin = widgets.Dropdown(options=wave_period_bin,value='Mid',description='Wave period',disabled=False),\n",
    "                wave_direction_bin = widgets.Dropdown(options=wave_direction_bin,value='NNE',description='Wave direction',disabled=False),\n",
    "                wind_u_bin = widgets.Dropdown(options=wind_u_bin,value='Mid',description='Wind u',disabled=False),\n",
    "                wind_v_bin = widgets.Dropdown(options=wind_v_bin,value='Mid',description='Wind v',disabled=False),\n",
    "                proj_time = widgets.IntSlider(min=2020,max=2150,step=10,value=2020,description='SLR prediction')\n",
    "               )\n",
    "\n",
    "\n",
    "map_osm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "cite2c": {
   "citations": {
    "2344856/I2LE4LVY": {
     "DOI": "10.1029/2019PA003589",
     "author": [
      {
       "family": "Bengtson",
       "given": "Shannon A."
      },
      {
       "family": "Meissner",
       "given": "Katrin J."
      },
      {
       "family": "Menviel",
       "given": "Laurie"
      },
      {
       "family": "A. Sisson",
       "given": "Scott"
      },
      {
       "family": "Wilkin",
       "given": "John"
      }
     ],
     "container-title": "Paleoceanography and Paleoclimatology",
     "container-title-short": "Paleoceanography and Paleoclimatology",
     "id": "2344856/I2LE4LVY",
     "issued": {
      "day": 17,
      "month": 5,
      "year": 2019
     },
     "journalAbbreviation": "Paleoceanography and Paleoclimatology",
     "note": "Citation Key: bengtson2019evaluating",
     "page": "1022-1036",
     "page-first": "1022",
     "title": "Evaluating the extent of North Atlantic Deep Water and the mean Atlantic δ<sup>13</sup>C from statistical reconstructions",
     "type": "article-journal",
     "volume": "34"
    },
    "2344856/V5HIVSEQ": {
     "DOI": "10.1017/S0263593300020782",
     "URL": "https://www.cambridge.org/core/journals/earth-and-environmental-science-transactions-of-royal-society-of-edinburgh/article/an-alternative-astronomical-calibration-of-the-lower-pleistocene-timescale-based-on-odp-site-677/D02E93BFBF418256AD00642C8A98277C",
     "abstract": "Ocean Drilling Program (ODP) Site 677 provided excellent material for high resolution stable isotope analysis of both benthonic and planktonic foraminifera through the entire Pleistocene and upper Pliocene. The oxygen isotope record is readily correlated with the SPECMAP stack (Imbrie et al. 1984) and with the record from DSDP 607 (Ruddiman et al. 1986) but a significantly better match with orbital models is obtained by departing from the timescale proposed by these authors below Stage 16 (620 000 years). It is the stronger contribution from the precession signal in the record from ODP Site 677 that provides the basis for the revised timescale. Our proposed modification to the timescale would imply that the currently adopted radiometric dates for the Matuyama–Brunhes boundary, the Jaramillo and Olduvai Subchrons and the Gauss–Matuyama boundary underestimate their true astronomical ages by between 5 and 7%.",
     "accessed": {
      "day": 19,
      "month": 5,
      "year": 2020
     },
     "author": [
      {
       "family": "Shackleton",
       "given": "N. J."
      },
      {
       "family": "Berger",
       "given": "A."
      },
      {
       "family": "Peltier",
       "given": "W. R."
      }
     ],
     "container-title": "Earth and Environmental Science Transactions of The Royal Society of Edinburgh",
     "id": "2344856/V5HIVSEQ",
     "issue": "4",
     "issued": {
      "year": 1990
     },
     "language": "en",
     "note": "citation key: shackleton1990alternative",
     "page": "251-261",
     "page-first": "251",
     "title": "An alternative astronomical calibration of the lower Pleistocene timescale based on ODP Site 677",
     "type": "article-journal",
     "volume": "81"
    }
   }
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "260px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "744px",
    "left": "1262px",
    "right": "20px",
    "top": "135px",
    "width": "279px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
