{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the most contains the latest version of the time dependent BN modeling for Tarawa, Kiribati."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-10T02:18:06.245034Z",
     "start_time": "2021-06-10T02:18:06.200060Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-10T02:18:09.215577Z",
     "start_time": "2021-06-10T02:18:06.246033Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabling notebook extension jupyter-leaflet/extension...\r\n",
      "      - Validating: \u001b[32mOK\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime, time, timedelta\n",
    "import pysmile\n",
    "import pysmile_license\n",
    "import sys\n",
    "import json\n",
    "sys.path.append('/src/python_classes')\n",
    "import rpy2\n",
    "# os.environ['R_HOME'] = 'C:\\ProgramData\\Anaconda3\\Lib\\R'\n",
    "# %load_ext rpy2.ipython\n",
    "!jupyter nbextension enable --py --sys-prefix ipyleaflet\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "from ipyleaflet import *\n",
    "import ipywidgets as widgets\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import geojson\n",
    "import folium\n",
    "from folium.plugins import FloatImage as FloatImage\n",
    "from colormap import rgb2hex\n",
    "import rpy2\n",
    "os.environ['R_HOME'] = '/lib/R'\n",
    "%load_ext rpy2.ipython\n",
    "\n",
    "from BNModel import BNModel\n",
    "\n",
    "from preprocessing_all_points import *\n",
    "from preprocessing_points_spatially_temporally import *\n",
    "from compile_model_t import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-10T02:18:09.301509Z",
     "start_time": "2021-06-10T02:18:09.217559Z"
    }
   },
   "outputs": [],
   "source": [
    "# ### set location of file storage\n",
    "# folder = 'BN_antonio_data'\n",
    "# try:\n",
    "#     os.makedirs(folder)\n",
    "# except FileExistsError:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-10T02:18:16.558430Z",
     "start_time": "2021-06-10T02:18:09.303508Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import and preprocess data\n",
    "df_lagoon_profiles,df_ocean_profiles,inundation_dict,winds_dict,waves_dict,tide_dict,sla_dict,time_dict = \\\n",
    "    loading_tarawa_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Variable Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-10T02:19:00.324519Z",
     "start_time": "2021-06-10T02:19:00.237568Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def initialise_model_dictionaries():\n",
    "    #### Don't include spaces in bin names. if no discretisation, just leave out that key\n",
    "    lagoon_model_dict = {\n",
    "        'variables':{\n",
    "            'wind_u':{\n",
    "                'label':'Wind u vector (m/s)',\n",
    "                'discretisation':{\n",
    "                    'n_bins':5,\n",
    "                    'strategy':'kmeans',\n",
    "                    'bin_names':['VeryLow','Low','Mid','High','VeryHigh']\n",
    "                },\n",
    "                'child_nodes':['TWL_less_Tide']\n",
    "            },\n",
    "            'wind_v':{\n",
    "                'label':r'Wind v vector (m/s)',\n",
    "                'discretisation':{\n",
    "                    'n_bins':5,\n",
    "                    'strategy':'uniform',\n",
    "                    'bin_names':['VeryLow','Low','Mid','High','VeryHigh']\n",
    "                },\n",
    "                'child_nodes':['TWL_less_Tide']\n",
    "            },\n",
    "            'Hs_offshore':{\n",
    "                'label':'Offshore wave height (m)',\n",
    "                'discretisation':{\n",
    "                    'n_bins':5,\n",
    "                    'strategy':'kmeans',\n",
    "                    'bin_names':['VeryLow','Low','Mid','HighMid','VeryHigh']\n",
    "                },\n",
    "                'child_nodes':['TWL_less_Tide']\n",
    "            },\n",
    "            'Tm_offshore':{\n",
    "                'label':'Offshore wave period (s)',\n",
    "                'discretisation':{\n",
    "                    'n_bins':5,\n",
    "                    'strategy':'kmeans',\n",
    "                    'bin_names':['VeryLow','Low','Mid','High','VeryHigh']\n",
    "                },\n",
    "                'child_nodes':['TWL_less_Tide']\n",
    "            },\n",
    "            'Dir_offshore':{\n",
    "                'label':r'Offshore wave direction (degrees)',\n",
    "                'discretisation':{\n",
    "                    'n_bins':8,\n",
    "                    'strategy':'kmeans',\n",
    "                    'bin_names':['NNE','ENE','ESE','SSE','SSW','WSW','WNW','NNW']\n",
    "                },\n",
    "                'child_nodes':['TWL_less_Tide']\n",
    "            },\n",
    "            'TWL':{\n",
    "                'label':'Total water level (m)',\n",
    "                'discretisation':{\n",
    "                    'n_bins':7,\n",
    "                    'strategy':'binned',\n",
    "                    'bin_names':['VeryLow','Low','LowMid','Mid','MidHigh','High','VeryHigh'],\n",
    "                    'bin_edges':np.arange(-1,3.0,0.5)\n",
    "                },\n",
    "                'child_nodes':[]\n",
    "            },\n",
    "            'TWL_less_Tide':{\n",
    "                'label':'Total water level less tide (m)',\n",
    "                'discretisation':{\n",
    "                    'n_bins':5,\n",
    "                    'strategy':'kmeans',\n",
    "                    'bin_names':['VeryLow','Low','Mid','High','VeryHigh']\n",
    "                },\n",
    "                'child_nodes':['TWL']\n",
    "            },\n",
    "            'MSL':{\n",
    "                'label':'Mean sea level (m)',\n",
    "                'discretisation':{\n",
    "                    'n_bins':5,\n",
    "                    'strategy':'kmeans',\n",
    "                    'bin_names':['VeryLow','Low','Mid','High','VeryHigh']\n",
    "                },\n",
    "                'child_nodes':['TWL_less_Tide']\n",
    "            },\n",
    "            'Tide':{\n",
    "                'label':'Tide (m)',\n",
    "                'discretisation':{\n",
    "                    'n_bins':5,\n",
    "                    'strategy':'kmeans',\n",
    "                    'bin_names':['VeryLow','Low','Mid','High','VeryHigh']\n",
    "                },\n",
    "                'child_nodes':['TWL']\n",
    "            }\n",
    "        },\n",
    "        'training_frac':0.8,\n",
    "        'bootstrap_reps':1\n",
    "    }\n",
    "    ocean_model_dict = {\n",
    "       'variables':{\n",
    "           'Tm_offshore':{\n",
    "                'label':'Wave period offshore (?)',\n",
    "                'discretisation':{\n",
    "                    'n_bins':5,\n",
    "                    'strategy':'kmeans',\n",
    "                    'bin_names':['VeryLow','Low','Mid','High','VeryHigh']\n",
    "                },\n",
    "                'child_nodes':['TWL_less_Tide']\n",
    "            },\n",
    "            'Hs_offshore':{\n",
    "                'label':'Wave height offshore (m)',\n",
    "                'discretisation':{\n",
    "                    'n_bins':5,\n",
    "                    'strategy':'kmeans',\n",
    "                    'bin_names':['VeryLow','Low','Mid','High','VeryHigh']\n",
    "                },\n",
    "                'child_nodes':['TWL_less_Tide']\n",
    "            },\n",
    "            'Dir_offshore':{\n",
    "                'label':'Wave direction offshore (degrees)',\n",
    "                'discretisation':{\n",
    "                    'n_bins':8,\n",
    "                    'strategy':'kmeans',\n",
    "                    'bin_names':['NNE','ENE','ESE','SSE','SSW','WSW','WNW','NNW']\n",
    "                },\n",
    "                'child_nodes':['TWL_less_Tide']\n",
    "            },\n",
    "            'MSL':{\n",
    "                'label':'Mean sea level (m)',\n",
    "                'discretisation':{\n",
    "                    'n_bins':5,\n",
    "                    'strategy':'kmeans',\n",
    "                    'bin_names':['VeryLow','Low','Mid','High','VeryHigh']\n",
    "                },\n",
    "                'child_nodes':['TWL_less_Tide']\n",
    "            },\n",
    "            'Tide':{\n",
    "                'label':'Tide (m)',\n",
    "                'discretisation':{\n",
    "                    'n_bins':5,\n",
    "                    'strategy':'kmeans',\n",
    "                    'bin_names':['VeryLow','Low','Mid','High','VeryHigh']\n",
    "                },\n",
    "                'child_nodes':['TWL']\n",
    "            },\n",
    "            'TWL':{\n",
    "                'label':'Total water level (m)',\n",
    "                'discretisation':{\n",
    "                    'n_bins':7,\n",
    "                    'strategy':'binned',\n",
    "                    'bin_names':['VeryLow','Low','LowMid','Mid','MidHigh','High','VeryHigh'],\n",
    "                    'bin_edges':np.arange(-1,3.0,0.5)\n",
    "                },\n",
    "                'child_nodes':[]\n",
    "            },\n",
    "            'TWL_less_Tide':{\n",
    "                'label':'Total water level less tide (m)',\n",
    "                'discretisation':{\n",
    "                    'n_bins':5,\n",
    "                    'strategy':'kmeans',\n",
    "                    'bin_names':['VeryLow','Low','Mid','High','VeryHigh']\n",
    "                },\n",
    "                'child_nodes':['TWL']\n",
    "            },\n",
    "            'reef_width':{\n",
    "                'label':'Reef width (m)',\n",
    "                'discretisation':{\n",
    "                    'n_bins':5,\n",
    "                    'strategy':'kmeans',\n",
    "                    'bin_names':['VeryLow','Low','Mid','High','VeryHigh']\n",
    "                },\n",
    "                'child_nodes':['TWL_less_Tide']\n",
    "            },\n",
    "            'reef_depth':{\n",
    "                'label':'Reef depth (m)',\n",
    "                'discretisation':{\n",
    "                    'n_bins':5,\n",
    "                    'strategy':'kmeans',\n",
    "                    'bin_names':['VeryLow','Low','Mid','High','VeryHigh']\n",
    "                },\n",
    "                'child_nodes':['TWL_less_Tide']\n",
    "            },\n",
    "            'forereef_slope':{\n",
    "                'label':'Fore reef slope (degrees)',\n",
    "                'discretisation':{\n",
    "                    'n_bins':5,\n",
    "                    'strategy':'kmeans',\n",
    "                    'bin_names':['VeryLow','Low','Mid','High','VeryHigh']\n",
    "                },\n",
    "                'child_nodes':['TWL_less_Tide']\n",
    "            },\n",
    "            'shore_dir':{\n",
    "                'label':'Shoreline direction (degrees)',\n",
    "                'discretisation':{\n",
    "                    'n_bins':3,\n",
    "                    'strategy':'kmeans',\n",
    "                    'bin_names':['NE','S','NW']\n",
    "                },\n",
    "                'child_nodes':['TWL_less_Tide']\n",
    "            }\n",
    "       },\n",
    "        'training_frac':0.8,\n",
    "        'bootstrap_reps':1\n",
    "    }\n",
    "    return(lagoon_model_dict,ocean_model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_locator(value,bin_edges):\n",
    "    '''\n",
    "    function used for determining the index of the appropriate bin for a numerical value.\n",
    "    '''\n",
    "    i=0\n",
    "    for edge_1,edge_2 in zip(bin_edges[:-1],bin_edges[1:]):\n",
    "        if (value>edge_1)&(value<=edge_2):\n",
    "            loc_bin = i\n",
    "        else:\n",
    "            i+=1\n",
    "            continue\n",
    "\n",
    "    if value<=bin_edges[0]:\n",
    "        loc_bin = 0\n",
    "\n",
    "    if value>=bin_edges[-1]:\n",
    "        loc_bin = len(bin_edges)-2\n",
    "\n",
    "    return(loc_bin)\n",
    "\n",
    "def model_location(model_dict,location_details,evidence_dict,variable_list):\n",
    "    \n",
    "    '''\n",
    "    function for adding the location information for one side model to the evidence dictionary\n",
    "    '''\n",
    "    \n",
    "    for variable in variable_list:\n",
    "\n",
    "        bin_edges = model_dict['variables'][variable]['bin_edges'][0]\n",
    "        value = location_details[variable]\n",
    "\n",
    "        var_bin = bin_locator(value,bin_edges)\n",
    "        \n",
    "        evidence_array = [0]*(len(bin_edges)-1)\n",
    "        evidence_array[var_bin] = 1\n",
    "        \n",
    "        evidence_dict.update({\n",
    "            variable:evidence_array\n",
    "        })\n",
    "\n",
    "    # Add evidence to model dict\n",
    "    model_location_dict = BNModel().add_evidence_to_dict(model_dict,evidence_dict)\n",
    "    \n",
    "    # Set evidence and get beliefs\n",
    "    model_location_dict = BNModel().update_evidence(model_location_dict)\n",
    "    \n",
    "    return(model_location_dict)\n",
    "\n",
    "def location_probabilities(evidence_dict,model_dict,variable_list,df_profiles):\n",
    "    '''\n",
    "    \n",
    "    Function for setting evidence and determing probabilties for twl at each point around the island based \n",
    "    on the reef characteristics at each location\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    location_probabilities_dict = {}\n",
    "    \n",
    "    for index,row in df_profiles.iterrows():\n",
    "\n",
    "        model_location_dict = model_location(model_dict,row,evidence_dict,variable_list)\n",
    "        location_probabilities = model_location_dict['variables']['TWL']['resulting_probs'][0]\n",
    "\n",
    "        df_location_probabilities = pd.DataFrame.from_dict(location_probabilities,orient='index')\n",
    "        \n",
    "        largest_cat = df_location_probabilities.idxmax()[0]\n",
    "\n",
    "        location_probabilities_dict.update({\n",
    "            (row.reef_long,row.reef_lat):\\\n",
    "                model_dict['variables']['TWL']['discretisation']['bin_names'].index(largest_cat)\n",
    "        })\n",
    "        \n",
    "    return(location_probabilities_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrapping the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_figure(\n",
    "#     view,tide_bin,wave_height_bin,wave_period_bin,wave_direction_bin,wind_u_bin,wind_v_bin,proj_time,time_min,time_max\n",
    "#     ):\n",
    "    \n",
    "#     for lower_idx,upper_idx in zip(np.arange(time_min,len(inundation_dict['Time']),100),np.arange(100+time_min,len(inundation_dict['Time']),100)):\n",
    "#         print(lower_idx,upper_idx)\n",
    "\n",
    "    \n",
    "#     # Extract the right model from the dictionary of model\n",
    "#     lagoon_model_dict = model_dicts_through_time_dict[time_max]['lagoon']\n",
    "#     ocean_model_dict = model_dicts_through_time_dict[time_min]['ocean']\n",
    "    \n",
    "#     ########### get the MSL bin based on slider value\n",
    "#     msl_proj = SLR_proj_extractor(SL_proj_dict,'k14','26','{}'.format(proj_time))\n",
    "#     bin_count = bin_locator(msl_proj,ocean_model_dict['variables']['MSL']['bin_edges'][0])\n",
    "#     msl_bin = ocean_model_dict['variables']['MSL']['discretisation']['bin_names'][bin_count]\n",
    "   \n",
    "#     ################################################\n",
    "    \n",
    "#     # Create an empty dictionary for the evidence and populate as you go\n",
    "#     ocean_evidence_dict = {}\n",
    "    \n",
    "#     for var_bin,var_name in zip([tide_bin,msl_bin,wave_height_bin,wave_period_bin,wave_direction_bin],\n",
    "#                                 ['Tide','MSL','Hs_offshore','Tm_offshore','Dir_offshore']):\n",
    "\n",
    "#         ## Set in the evidence dict to be as indicated in the dropdown\n",
    "#         bin_index = ocean_model_dict['variables'][var_name]['discretisation']['bin_names'].index(var_bin)\n",
    "#         # Create a list of the tide evidence (all zero except as indicated by dropdown. Dropdown=1)\n",
    "#         evidence = [0 for x in ocean_model_dict['variables'][var_name]['discretisation']['bin_names']]\n",
    "#         evidence[bin_index] = 1\n",
    "#         ocean_evidence_dict.update({\n",
    "#             var_name:evidence\n",
    "#         })\n",
    "    \n",
    "#     # Create a list of variables that are location specific to set as evidence in the network\n",
    "#     variable_list = ['reef_width','reef_depth','forereef_slope','shore_dir']\n",
    "    \n",
    "#     # get the probability dictionary\n",
    "#     location_probabilities_dict = location_probabilities(ocean_evidence_dict,ocean_model_dict,variable_list,df_ocean_profiles)\n",
    "    \n",
    "#     # Create dataframe to plot\n",
    "#     df_twl_locations = pd.DataFrame.from_dict(location_probabilities_dict,orient='index').rename(columns={0:'most_likely_twl'})\n",
    "#     df_twl_locations['long'] = [long for long,lat in df_twl_locations.index]\n",
    "#     df_twl_locations['lat'] = [lat for long,lat in df_twl_locations.index]\n",
    "#     df_twl_locations.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "#     #####################################################################\n",
    "    \n",
    "#     # Create an empty dictionary for the evidence and populate as you go\n",
    "#     lagoon_evidence_dict = {}\n",
    "    \n",
    "#     for var_bin,var_name in zip([tide_bin,msl_bin,wave_height_bin,wave_period_bin,wave_direction_bin,wind_u_bin,wind_v_bin],\n",
    "#                                 ['Tide','MSL','Hs_offshore','Tm_offshore','Dir_offshore','wind_u','wind_v']):\n",
    "\n",
    "#         ## Set in the evidence dict to be as indicated in the dropdown\n",
    "#         bin_index = lagoon_model_dict['variables'][var_name]['discretisation']['bin_names'].index(var_bin)\n",
    "#         # Create a list of the tide evidence (all zero except as indicated by dropdown. Dropdown=1)\n",
    "#         evidence = [0 for x in lagoon_model_dict['variables'][var_name]['discretisation']['bin_names']]\n",
    "#         evidence[bin_index] = 1\n",
    "#         lagoon_evidence_dict.update({\n",
    "#             var_name:evidence\n",
    "#         })\n",
    "    \n",
    "#     # Create a list of variables that are location specific to set as evidence in the network\n",
    "#     variable_list = []\n",
    "    \n",
    "#     # get the probability dictionary\n",
    "#     location_probabilities_dict = location_probabilities(lagoon_evidence_dict,lagoon_model_dict,variable_list,df_lagoon_profiles)\n",
    "    \n",
    "#     # Create dataframe to plot\n",
    "#     df_twl_locations = pd.DataFrame.from_dict(location_probabilities_dict,orient='index').rename(columns={0:'most_likely_twl'})\n",
    "#     df_twl_locations['long'] = [long for long,lat in df_twl_locations.index]\n",
    "#     df_twl_locations['lat'] = [lat for long,lat in df_twl_locations.index]\n",
    "#     df_twl_locations.reset_index(drop=True,inplace=True)\n",
    "\n",
    "#     return()\n",
    "\n",
    "# # compile the figure\n",
    "# lagoon_model_dict,ocean_model_dict = initialise_model_dictionaries()\n",
    "# tide_bins = ocean_model_dict['variables']['Tide']['discretisation']['bin_names']\n",
    "# wave_height_bins = ocean_model_dict['variables']['Hs_offshore']['discretisation']['bin_names']\n",
    "# wave_period_bin = ocean_model_dict['variables']['Tm_offshore']['discretisation']['bin_names']\n",
    "# wave_direction_bin = ocean_model_dict['variables']['Dir_offshore']['discretisation']['bin_names']\n",
    "# wind_u_bin = lagoon_model_dict['variables']['wind_u']['discretisation']['bin_names']\n",
    "# wind_v_bin = lagoon_model_dict['variables']['wind_u']['discretisation']['bin_names']\n",
    "# time = list(df_lagoon.time) \n",
    "\n",
    "# # Create the plot with the widget\n",
    "# interact_manual(test_figure,\n",
    "#                 view = widgets.Dropdown(options=['Map','Satellite'],value='Map',description='View type',disabled=False),\n",
    "#                 tide_bin = widgets.Dropdown(options=tide_bins,value='Mid',description='Tide',disabled=False),\n",
    "#                 wave_height_bin = widgets.Dropdown(options=wave_height_bins,value='Mid',description='Wave height',disabled=False),\n",
    "#                 wave_period_bin = widgets.Dropdown(options=wave_period_bin,value='Mid',description='Wave period',disabled=False),\n",
    "#                 wave_direction_bin = widgets.Dropdown(options=wave_direction_bin,value='NNE',description='Wave direction',disabled=False),\n",
    "#                 wind_u_bin = widgets.Dropdown(options=wind_u_bin,value='Mid',description='Wind u',disabled=False),\n",
    "#                 wind_v_bin = widgets.Dropdown(options=wind_v_bin,value='Mid',description='Wind v',disabled=False),\n",
    "#                 proj_time = widgets.IntSlider(min=2020,max=2150,step=10,value=2020,description='SLR prediction'),\n",
    "#                 time_min = widgets.Dropdown(options=time,value=time[0],description='Time',disabled=False),\n",
    "#                 time_max = widgets.Dropdown(options=time,value=time[0],description='Time',disabled=False)\n",
    "#                )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One network per time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_discretization.py:187: UserWarning: Feature 0 is constant and will be replaced with 0.\n",
      "  warnings.warn(\"Feature %d is constant and will be \"\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_discretization.py:187: UserWarning: Feature 0 is constant and will be replaced with 0.\n",
      "  warnings.warn(\"Feature %d is constant and will be \"\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_discretization.py:187: UserWarning: Feature 0 is constant and will be replaced with 0.\n",
      "  warnings.warn(\"Feature %d is constant and will be \"\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_discretization.py:187: UserWarning: Feature 0 is constant and will be replaced with 0.\n",
      "  warnings.warn(\"Feature %d is constant and will be \"\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_discretization.py:187: UserWarning: Feature 0 is constant and will be replaced with 0.\n",
      "  warnings.warn(\"Feature %d is constant and will be \"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_dicts_through_time_dict = {}\n",
    "\n",
    "time_min = inundation_dict['Time'][0]\n",
    "time_step = timedelta(hours=24)\n",
    "max_steps = 7\n",
    "\n",
    "times_for_model = []\n",
    "\n",
    "for step in np.arange(0,max_steps,1):\n",
    "    time_at_step = time_min+time_step*step\n",
    "    \n",
    "    times_for_model.append(time_at_step)\n",
    "    \n",
    "times_for_model = times_for_model[:10]\n",
    "    \n",
    "for time_min,time_max in zip(times_for_model[:-1],times_for_model[1:]):\n",
    "    lower_idx = np.abs([x-time_min for x in inundation_dict['Time']]).argmin()\n",
    "    upper_idx = np.abs([x-time_max for x in inundation_dict['Time']]).argmin()\n",
    "       \n",
    "    inundation_time_slice_dict = {var:inundation_dict[var][lower_idx:upper_idx,:] for var in ['TWL','Tide']}\n",
    "    inundation_time_slice_dict['Time'] = inundation_dict['Time'][lower_idx:upper_idx]\n",
    "    inundation_time_slice_dict['Ptos'] = inundation_dict['Ptos']\n",
    "    winds_time_slice_dict = {\n",
    "        'wind_u':winds_dict['wind_u'][lower_idx:upper_idx],'wind_v':winds_dict['wind_v'][lower_idx:upper_idx]}\n",
    "    waves_time_slice_dict = {var:waves_dict[var][lower_idx:upper_idx,:] for var in ['Diro','Hso','Tmo','Tpo']}\n",
    "    waves_time_slice_dict['Timeo'] = waves_dict['Timeo'][lower_idx:upper_idx]\n",
    "    \n",
    "    tide_time_slice_dict = {'Tide':tide_dict['Tide'][lower_idx:upper_idx]}\n",
    "    sla_time_slice_dict = {'MSL':sla_dict['MSL'][lower_idx:upper_idx]}\n",
    "    time_slice_dict = {'time':time_dict['time'][lower_idx:upper_idx]}\n",
    "    \n",
    "    if time_min==times_for_model[0]:\n",
    "        lagoon_model_dict,ocean_model_dict = initialise_model_dictionaries()\n",
    "        predicted_lag_variables = []\n",
    "    else:\n",
    "        predicted_lag_variables = ['TWL_t_1']\n",
    "        for var in predicted_lag_variables:\n",
    "            df_ocean_profiles[var] = 0#[item for key,item in ocean_probabilities_dict.items()]\n",
    "            \n",
    "        ocean_model_dict['variables'].update({\n",
    "                'TWL_t_1':{\n",
    "                'label':'Total water level bin at t-1 (1-5?)',\n",
    "                'discretisation':{\n",
    "                    'n_bins':5,\n",
    "                    'strategy':'kmeans',\n",
    "                    'bin_names':['1','2','3','4','5']\n",
    "                },\n",
    "                'child_nodes':['TWL']\n",
    "            }\n",
    "        })\n",
    "\n",
    "    df_ocean,df_lagoon,ocean_data_dict,lagoon_data_dict = \\\n",
    "        preprocessing_points_spatially_temporally(df_lagoon_profiles,\n",
    "                                                  df_ocean_profiles,\n",
    "                                                  inundation_time_slice_dict,\n",
    "                                                  winds_time_slice_dict,\n",
    "                                                  waves_time_slice_dict,\n",
    "                                                  tide_time_slice_dict,\n",
    "                                                  sla_time_slice_dict,\n",
    "                                                  time_slice_dict,\n",
    "                                                  predicted_lag_variables)\n",
    "    \n",
    "    lagoon_model_dict,ocean_model_dict = create_BN_time_t(lagoon_model_dict,\n",
    "                                                          lagoon_data_dict,\n",
    "                                                          df_lagoon,\n",
    "                                                          ocean_model_dict,\n",
    "                                                          df_ocean,\n",
    "                                                          ocean_data_dict)    \n",
    "    \n",
    "    \n",
    "    # Create an empty evidence dict\n",
    "    evidence_dict = {}\n",
    "    \n",
    "    # Add evidence to model dict\n",
    "    ocean_model_dict = BNModel().add_evidence_to_dict(ocean_model_dict,evidence_dict)\n",
    "    lagoon_model_dict = BNModel().add_evidence_to_dict(lagoon_model_dict,evidence_dict)\n",
    "\n",
    "    # Set evidence and get beliefs\n",
    "    ocean_model_dict = BNModel().update_evidence(ocean_model_dict)\n",
    "    lagoon_model_dict = BNModel().update_evidence(lagoon_model_dict)\n",
    "    \n",
    "    # Get the resulting TWL probabilities (right now for a generic location)\n",
    "    resulting_probs_ocean = ocean_model_dict['variables']['TWL']['resulting_probs']\n",
    "    resulting_probs_lagoon = lagoon_model_dict['variables']['TWL']['resulting_probs']\n",
    "    \n",
    "    model_dicts_through_time_dict.update({\n",
    "        time_dict['time'][lower_idx]:{\n",
    "            'lagoon':lagoon_model_dict,\n",
    "            'ocean':ocean_model_dict\n",
    "        }\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'VeryLow': 0.057652865538091104,\n",
       "  'Low': 0.20021510002781004,\n",
       "  'LowMid': 0.22005644016611248,\n",
       "  'Mid': 0.24995197599207142,\n",
       "  'MidHigh': 0.18001784949472052,\n",
       "  'High': 0.07543820365882235,\n",
       "  'VeryHigh': 0.016667565122372167}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resulting_probs_lagoon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tide_bin' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_41/4017370530.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mocean_evidence_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m for var_bin,var_name in zip([tide_bin,msl_bin,wave_height_bin,wave_period_bin,wave_direction_bin],\n\u001b[0m\u001b[1;32m      5\u001b[0m                             ['Tide','MSL','Hs_offshore','Tm_offshore','Dir_offshore']):\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tide_bin' is not defined"
     ]
    }
   ],
   "source": [
    "# Create an empty dictionary for the evidence and populate as you go\n",
    "ocean_evidence_dict = {}\n",
    "\n",
    "for var_bin,var_name in zip([tide_bin,msl_bin,wave_height_bin,wave_period_bin,wave_direction_bin],\n",
    "                            ['Tide','MSL','Hs_offshore','Tm_offshore','Dir_offshore']):\n",
    "\n",
    "    ## Set in the evidence dict to be as indicated in the dropdown\n",
    "    bin_index = ocean_model_dict['variables'][var_name]['discretisation']['bin_names'].index(var_bin)\n",
    "    # Create a list of the tide evidence (all zero except as indicated by dropdown. Dropdown=1)\n",
    "    evidence = [0 for x in ocean_model_dict['variables'][var_name]['discretisation']['bin_names']]\n",
    "    evidence[bin_index] = 1\n",
    "    ocean_evidence_dict.update({\n",
    "        var_name:evidence\n",
    "    })\n",
    "\n",
    "# Create a list of variables that are location specific to set as evidence in the network\n",
    "variable_list = ['reef_width','reef_depth','forereef_slope','shore_dir']\n",
    "\n",
    "# get the probability dictionary\n",
    "location_probabilities_dict = location_probabilities(ocean_evidence_dict,ocean_model_dict,variable_list,df_ocean_profiles)\n",
    "\n",
    "# Create dataframe to plot\n",
    "df_twl_locations = pd.DataFrame.from_dict(location_probabilities_dict,orient='index').rename(columns={0:'most_likely_twl'})\n",
    "df_twl_locations['long'] = [long for long,lat in df_twl_locations.index]\n",
    "df_twl_locations['lat'] = [lat for long,lat in df_twl_locations.index]\n",
    "df_twl_locations.reset_index(drop=True,inplace=True)\n",
    "\n",
    "# data_ocean = data2geojson(df_twl_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(172.90162, 1.3804422): 3,\n",
       " (172.89642, 1.3572711): 3,\n",
       " (172.91862, 1.3429104): 3,\n",
       " (172.92461, 1.3422936): 3,\n",
       " (172.9299, 1.3429104): 3,\n",
       " (172.93386, 1.343439): 3,\n",
       " (172.93633, 1.3425579): 3,\n",
       " (172.93906, 1.3415007): 3,\n",
       " (172.9425, 1.3401792): 3,\n",
       " (172.94681, 1.3384171): 3,\n",
       " (172.95016, 1.3369194): 3,\n",
       " (172.95302, 1.3344084): 3,\n",
       " (172.95606, 1.3321618): 3,\n",
       " (172.96069, 1.3299592): 3,\n",
       " (172.96461, 1.3270518): 3,\n",
       " (172.9691, 1.3238361): 3,\n",
       " (172.97192, 1.3219419): 3,\n",
       " (172.97606, 1.3214133): 3,\n",
       " (172.97972, 1.3210168): 3,\n",
       " (172.9847, 1.3209287): 3,\n",
       " (172.98923, 1.3214573): 3,\n",
       " (172.99404, 1.3225145): 3,\n",
       " (172.99813, 1.322911): 3,\n",
       " (173.00302, 1.3241444): 3,\n",
       " (173.00703, 1.32551): 3,\n",
       " (173.00884, 1.3257743): 3,\n",
       " (173.01161, 1.327228): 3,\n",
       " (173.01448, 1.328065): 3,\n",
       " (173.01844, 1.3296509): 3,\n",
       " (173.0224, 1.3316332): 3,\n",
       " (173.02663, 1.3338798): 3,\n",
       " (173.03082, 1.3358401): 3,\n",
       " (173.03458, 1.3384391): 3,\n",
       " (173.03925, 1.3411703): 3,\n",
       " (173.04278, 1.3432848): 3,\n",
       " (173.04604, 1.3458398): 3,\n",
       " (173.04745, 1.3472494): 3,\n",
       " (173.04802, 1.347778): 3,\n",
       " (173.05058, 1.3493198): 3,\n",
       " (173.05238, 1.3500687): 3,\n",
       " (173.05542, 1.3510378): 3,\n",
       " (173.06, 1.3514343): 3,\n",
       " (173.06476, 1.3525796): 3,\n",
       " (173.06879, 1.3530642): 3,\n",
       " (173.07399, 1.3533285): 3,\n",
       " (173.07892, 1.3542095): 3,\n",
       " (173.08331, 1.3566324): 3,\n",
       " (173.08657, 1.3575134): 3,\n",
       " (173.08969, 1.3591874): 3,\n",
       " (173.0932, 1.3594296): 3,\n",
       " (173.09758, 1.3596719): 3,\n",
       " (173.10145, 1.3594296): 3,\n",
       " (173.10617, 1.3589451): 3,\n",
       " (173.11073, 1.3586367): 3,\n",
       " (173.1167, 1.3588349): 3,\n",
       " (173.12079, 1.3600243): 3,\n",
       " (173.12469, 1.3609714): 3,\n",
       " (173.12815, 1.3613459): 3,\n",
       " (173.13205, 1.3609274): 3,\n",
       " (173.13548, 1.3599803): 3,\n",
       " (173.14026, 1.3577997): 3,\n",
       " (173.14469, 1.3563901): 3,\n",
       " (173.14903, 1.3557954): 3,\n",
       " (173.15388, 1.3552888): 3,\n",
       " (173.15892, 1.3549804): 3,\n",
       " (173.16562, 1.3569848): 3,\n",
       " (173.16894, 1.3634383): 4,\n",
       " (173.17022, 1.3700901): 3,\n",
       " (173.16731, 1.3771824): 3,\n",
       " (173.16493, 1.381147): 4,\n",
       " (173.16026, 1.3839443): 3,\n",
       " (173.15744, 1.3878648): 4,\n",
       " (173.1541, 1.3901115): 4,\n",
       " (173.1507, 1.3928867): 4,\n",
       " (173.14634, 1.3945166): 4,\n",
       " (173.1444, 1.3959262): 4,\n",
       " (173.1422, 1.3969394): 3,\n",
       " (173.14097, 1.3980848): 4,\n",
       " (173.13978, 1.3989658): 4,\n",
       " (173.13797, 1.3995825): 4,\n",
       " (173.13608, 1.4010803): 4,\n",
       " (173.13326, 1.4030185): 4,\n",
       " (173.13106, 1.4052651): 3,\n",
       " (173.12855, 1.4067188): 3,\n",
       " (173.12564, 1.4081285): 3,\n",
       " (173.127, 1.406851): 3,\n",
       " (173.0919, 1.4477307): 4,\n",
       " (173.09445, 1.4460568): 4,\n",
       " (173.09753, 1.4428851): 3,\n",
       " (173.09912, 1.4403301): 4,\n",
       " (173.1022, 1.4362773): 4,\n",
       " (173.10097, 1.4382156): 4,\n",
       " (173.10511, 1.4346034): 4,\n",
       " (173.10714, 1.4331056): 4,\n",
       " (173.10934, 1.431696): 3,\n",
       " (173.11145, 1.4259693): 4,\n",
       " (173.11582, 1.4227536): 3,\n",
       " (173.11775, 1.4192294): 3,\n",
       " (173.1193, 1.416278): 3,\n",
       " (173.12145, 1.4138111): 4,\n",
       " (173.12454, 1.4107716): 3,\n",
       " (172.94959, 1.6406759): 3,\n",
       " (172.96221, 1.6437375): 3,\n",
       " (172.9654, 1.6378126): 3,\n",
       " (172.96904, 1.6328348): 4,\n",
       " (172.96996, 1.6267557): 4,\n",
       " (172.97009, 1.6222184): 4,\n",
       " (172.97172, 1.6181657): 4,\n",
       " (172.97199, 1.6150821): 3,\n",
       " (172.97199, 1.6129896): 3,\n",
       " (172.97293, 1.6084523): 4,\n",
       " (172.97366, 1.6051264): 4,\n",
       " (172.9752, 1.6019988): 4,\n",
       " (172.97496, 1.5981883): 3,\n",
       " (172.97551, 1.5946642): 4,\n",
       " (172.97692, 1.5912282): 3,\n",
       " (172.97871, 1.588431): 4,\n",
       " (172.97961, 1.5824179): 4,\n",
       " (172.97972, 1.5777705): 3,\n",
       " (172.98031, 1.5745548): 3,\n",
       " (172.98051, 1.5731451): 3,\n",
       " (172.98069, 1.5706562): 4,\n",
       " (172.98205, 1.5674845): 4,\n",
       " (172.98419, 1.5649075): 4,\n",
       " (172.98615, 1.5636961): 4,\n",
       " (172.98956, 1.5622644): 3,\n",
       " (172.99287, 1.5609208): 3,\n",
       " (172.99732, 1.5565377): 4,\n",
       " (172.9991, 1.5538065): 3,\n",
       " (173.00144, 1.550745): 4,\n",
       " (173.0019, 1.5444897): 4,\n",
       " (173.0026, 1.5408774): 4,\n",
       " (173.00503, 1.5375956): 4,\n",
       " (173.00663, 1.5339834): 4,\n",
       " (173.00805, 1.530262): 4,\n",
       " (173.01117, 1.527662): 4,\n",
       " (173.01379, 1.5246885): 4,\n",
       " (173.01727, 1.5221776): 4,\n",
       " (173.01804, 1.5152836): 4,\n",
       " (173.01791, 1.5112749): 4,\n",
       " (173.01981, 1.5081913): 4,\n",
       " (173.02075, 1.5058786): 4,\n",
       " (173.02282, 1.5041165): 3,\n",
       " (173.02573, 1.5023985): 3,\n",
       " (173.0271, 1.5005924): 3,\n",
       " (173.02846, 1.4992268): 3,\n",
       " (173.03093, 1.4972445): 4,\n",
       " (173.0326, 1.4931037): 4,\n",
       " (173.03428, 1.4903725): 4,\n",
       " (173.03639, 1.4876413): 3,\n",
       " (173.03851, 1.4855268): 3,\n",
       " (173.04022, 1.483941): 4,\n",
       " (173.04172, 1.4827516): 3,\n",
       " (173.0434, 1.4817825): 3,\n",
       " (173.04784, 1.479668): 3,\n",
       " (173.04943, 1.4758355): 3,\n",
       " (173.05135, 1.4715625): 3,\n",
       " (173.05344, 1.4687873): 3,\n",
       " (173.05643, 1.4673116): 3,\n",
       " (173.06044, 1.465131): 4,\n",
       " (173.06304, 1.464294): 3,\n",
       " (173.06795, 1.4614748): 3,\n",
       " (173.06952, 1.4592722): 3,\n",
       " (173.0704, 1.4575982): 3,\n",
       " (173.07463, 1.4563648): 3,\n",
       " (173.07859, 1.4533693): 3,\n",
       " (173.08555, 1.4506381): 4,\n",
       " (173.08361, 1.4516953): 3,\n",
       " (173.08828, 1.4489642): 3,\n",
       " (172.93274, 1.6159015): 3,\n",
       " (172.93545, 1.6199718): 3,\n",
       " (172.938, 1.6230994): 3,\n",
       " (172.93968, 1.626183): 3,\n",
       " (172.9408, 1.6281653): 3,\n",
       " (172.94166, 1.6320639): 3,\n",
       " (172.94424, 1.6354558): 3,\n",
       " (172.94703, 1.6386716): 3,\n",
       " (172.89827, 1.3692531): 3,\n",
       " (172.90065, 1.3462583): 3,\n",
       " (172.95393, 1.6455877): 3,\n",
       " (173.04952, 1.3487031): 3,\n",
       " (173.05146, 1.3496282): 3}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_probabilities_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(172.90162, 1.3804422)</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(172.89642, 1.3572711)</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(172.91862, 1.3429104)</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(172.92461, 1.3422936)</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(172.9299, 1.3429104)</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(172.89827, 1.3692531)</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(172.90065, 1.3462583)</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(172.95393, 1.6455877)</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(173.04952, 1.3487031)</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(173.05146, 1.3496282)</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0\n",
       "(172.90162, 1.3804422)  3\n",
       "(172.89642, 1.3572711)  3\n",
       "(172.91862, 1.3429104)  3\n",
       "(172.92461, 1.3422936)  3\n",
       "(172.9299, 1.3429104)   3\n",
       "...                    ..\n",
       "(172.89827, 1.3692531)  3\n",
       "(172.90065, 1.3462583)  3\n",
       "(172.95393, 1.6455877)  3\n",
       "(173.04952, 1.3487031)  3\n",
       "(173.05146, 1.3496282)  3\n",
       "\n",
       "[182 rows x 1 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(location_probabilities_dict,orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TWL</th>\n",
       "      <th>Tide</th>\n",
       "      <th>MSL</th>\n",
       "      <th>wind_u</th>\n",
       "      <th>wind_v</th>\n",
       "      <th>time</th>\n",
       "      <th>TWL_less_Tide</th>\n",
       "      <th>Hs_offshore</th>\n",
       "      <th>Tm_offshore</th>\n",
       "      <th>Dir_offshore</th>\n",
       "      <th>long</th>\n",
       "      <th>lat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.208591</td>\n",
       "      <td>0.107750</td>\n",
       "      <td>0.088471</td>\n",
       "      <td>0.207214</td>\n",
       "      <td>-1.113144</td>\n",
       "      <td>1993-01-06 00:00:00.000000</td>\n",
       "      <td>0.100841</td>\n",
       "      <td>0.919050</td>\n",
       "      <td>7.219531</td>\n",
       "      <td>243.438797</td>\n",
       "      <td>172.92263</td>\n",
       "      <td>1.358684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.558604</td>\n",
       "      <td>0.452697</td>\n",
       "      <td>0.088416</td>\n",
       "      <td>0.597412</td>\n",
       "      <td>-1.259857</td>\n",
       "      <td>1993-01-06 00:59:59.999997</td>\n",
       "      <td>0.105907</td>\n",
       "      <td>0.905869</td>\n",
       "      <td>7.184422</td>\n",
       "      <td>242.904663</td>\n",
       "      <td>172.92263</td>\n",
       "      <td>1.358684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.814906</td>\n",
       "      <td>0.713712</td>\n",
       "      <td>0.088361</td>\n",
       "      <td>0.734024</td>\n",
       "      <td>-1.445007</td>\n",
       "      <td>1993-01-06 02:00:00.000003</td>\n",
       "      <td>0.101193</td>\n",
       "      <td>0.894031</td>\n",
       "      <td>7.136898</td>\n",
       "      <td>242.697632</td>\n",
       "      <td>172.92263</td>\n",
       "      <td>1.358684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.926768</td>\n",
       "      <td>0.825621</td>\n",
       "      <td>0.088307</td>\n",
       "      <td>0.645584</td>\n",
       "      <td>-2.000870</td>\n",
       "      <td>1993-01-06 03:00:00.000000</td>\n",
       "      <td>0.101147</td>\n",
       "      <td>0.882968</td>\n",
       "      <td>7.080943</td>\n",
       "      <td>242.759918</td>\n",
       "      <td>172.92263</td>\n",
       "      <td>1.358684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.859453</td>\n",
       "      <td>0.758048</td>\n",
       "      <td>0.088252</td>\n",
       "      <td>0.945312</td>\n",
       "      <td>-3.432281</td>\n",
       "      <td>1993-01-06 03:59:59.999997</td>\n",
       "      <td>0.101405</td>\n",
       "      <td>0.872668</td>\n",
       "      <td>7.023418</td>\n",
       "      <td>243.057816</td>\n",
       "      <td>172.92263</td>\n",
       "      <td>1.358684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3615</th>\n",
       "      <td>0.267540</td>\n",
       "      <td>-0.254680</td>\n",
       "      <td>0.087432</td>\n",
       "      <td>3.178680</td>\n",
       "      <td>0.185455</td>\n",
       "      <td>1993-01-06 18:59:59.999997</td>\n",
       "      <td>0.522221</td>\n",
       "      <td>0.213412</td>\n",
       "      <td>1.875810</td>\n",
       "      <td>258.507080</td>\n",
       "      <td>172.97082</td>\n",
       "      <td>1.568399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3616</th>\n",
       "      <td>-0.007965</td>\n",
       "      <td>-0.559890</td>\n",
       "      <td>0.087378</td>\n",
       "      <td>2.214493</td>\n",
       "      <td>0.678818</td>\n",
       "      <td>1993-01-06 20:00:00.000003</td>\n",
       "      <td>0.551925</td>\n",
       "      <td>0.192730</td>\n",
       "      <td>1.583964</td>\n",
       "      <td>258.807404</td>\n",
       "      <td>172.97082</td>\n",
       "      <td>1.568399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3617</th>\n",
       "      <td>-0.161496</td>\n",
       "      <td>-0.737260</td>\n",
       "      <td>0.087323</td>\n",
       "      <td>1.777710</td>\n",
       "      <td>0.224762</td>\n",
       "      <td>1993-01-06 21:00:00.000000</td>\n",
       "      <td>0.575764</td>\n",
       "      <td>0.173490</td>\n",
       "      <td>1.431452</td>\n",
       "      <td>259.189728</td>\n",
       "      <td>172.97082</td>\n",
       "      <td>1.568399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3618</th>\n",
       "      <td>-0.152408</td>\n",
       "      <td>-0.730377</td>\n",
       "      <td>0.087268</td>\n",
       "      <td>2.006165</td>\n",
       "      <td>-0.687057</td>\n",
       "      <td>1993-01-06 21:59:59.999997</td>\n",
       "      <td>0.577969</td>\n",
       "      <td>0.164677</td>\n",
       "      <td>1.389180</td>\n",
       "      <td>259.917908</td>\n",
       "      <td>172.97082</td>\n",
       "      <td>1.568399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3619</th>\n",
       "      <td>0.028796</td>\n",
       "      <td>-0.529565</td>\n",
       "      <td>0.087214</td>\n",
       "      <td>2.519379</td>\n",
       "      <td>-0.897888</td>\n",
       "      <td>1993-01-06 23:00:00.000003</td>\n",
       "      <td>0.558360</td>\n",
       "      <td>0.173917</td>\n",
       "      <td>1.372500</td>\n",
       "      <td>260.956421</td>\n",
       "      <td>172.97082</td>\n",
       "      <td>1.568399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3620 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           TWL      Tide       MSL    wind_u    wind_v  \\\n",
       "0     0.208591  0.107750  0.088471  0.207214 -1.113144   \n",
       "1     0.558604  0.452697  0.088416  0.597412 -1.259857   \n",
       "2     0.814906  0.713712  0.088361  0.734024 -1.445007   \n",
       "3     0.926768  0.825621  0.088307  0.645584 -2.000870   \n",
       "4     0.859453  0.758048  0.088252  0.945312 -3.432281   \n",
       "...        ...       ...       ...       ...       ...   \n",
       "3615  0.267540 -0.254680  0.087432  3.178680  0.185455   \n",
       "3616 -0.007965 -0.559890  0.087378  2.214493  0.678818   \n",
       "3617 -0.161496 -0.737260  0.087323  1.777710  0.224762   \n",
       "3618 -0.152408 -0.730377  0.087268  2.006165 -0.687057   \n",
       "3619  0.028796 -0.529565  0.087214  2.519379 -0.897888   \n",
       "\n",
       "                           time  TWL_less_Tide  Hs_offshore  Tm_offshore  \\\n",
       "0    1993-01-06 00:00:00.000000       0.100841     0.919050     7.219531   \n",
       "1    1993-01-06 00:59:59.999997       0.105907     0.905869     7.184422   \n",
       "2    1993-01-06 02:00:00.000003       0.101193     0.894031     7.136898   \n",
       "3    1993-01-06 03:00:00.000000       0.101147     0.882968     7.080943   \n",
       "4    1993-01-06 03:59:59.999997       0.101405     0.872668     7.023418   \n",
       "...                         ...            ...          ...          ...   \n",
       "3615 1993-01-06 18:59:59.999997       0.522221     0.213412     1.875810   \n",
       "3616 1993-01-06 20:00:00.000003       0.551925     0.192730     1.583964   \n",
       "3617 1993-01-06 21:00:00.000000       0.575764     0.173490     1.431452   \n",
       "3618 1993-01-06 21:59:59.999997       0.577969     0.164677     1.389180   \n",
       "3619 1993-01-06 23:00:00.000003       0.558360     0.173917     1.372500   \n",
       "\n",
       "      Dir_offshore       long       lat  \n",
       "0       243.438797  172.92263  1.358684  \n",
       "1       242.904663  172.92263  1.358684  \n",
       "2       242.697632  172.92263  1.358684  \n",
       "3       242.759918  172.92263  1.358684  \n",
       "4       243.057816  172.92263  1.358684  \n",
       "...            ...        ...       ...  \n",
       "3615    258.507080  172.97082  1.568399  \n",
       "3616    258.807404  172.97082  1.568399  \n",
       "3617    259.189728  172.97082  1.568399  \n",
       "3618    259.917908  172.97082  1.568399  \n",
       "3619    260.956421  172.97082  1.568399  \n",
       "\n",
       "[3620 rows x 12 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lagoon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining times of interest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create an empty dictionary to have a look at how the resulting probabilties varied through time\n",
    "# resulting_probs_dict = {}\n",
    "\n",
    "# for time,model_dict['lagoon'] in model_dicts_through_time_dict.items():\n",
    "    \n",
    "#     #Create an empty dictionary of evidence for now\n",
    "#     evidence_dict = {}\n",
    "    \n",
    "#     # Add evidence to model dict\n",
    "#     model_location_dict = BNModel().add_evidence_to_dict(model_dict,evidence_dict)\n",
    "\n",
    "#     # Set evidence and get beliefs\n",
    "#     model_location_dict = BNModel().update_evidence(model_location_dict)\n",
    "    \n",
    "#     # Get the resulting TWL probabilities (right now for a generic location)\n",
    "#     resulting_probs = model_location_dict['variables']['TWL']['resulting_probs']\n",
    "    \n",
    "#     # Add the resulting probabilities to a dictionary\n",
    "#     resulting_probs_dict.update({\n",
    "#         time:resulting_probs[0]\n",
    "#     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resulting_probs_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load in the reef and shoreline profile information\n",
    "# df_ocean_profiles = pd.read_csv('/src/Dataset/D8_tarawa_inundation/Profiles_definition_outer_reef_xyxy_processed.txt')\n",
    "# df_lagoon_profiles = pd.read_csv('/src/Dataset/D8_tarawa_inundation/Profiles_definition_inner_lagoon_xyxy.txt',delim_whitespace=True,header=None)\n",
    "# df_lagoon_profiles.columns = ['reef_long','reef_lat','shore_long','shore_lat','reef_depth']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def bin_locator(value,bin_edges):\n",
    "#     '''\n",
    "#     function used for determining the index of the appropriate bin for a numerical value.\n",
    "#     '''\n",
    "#     i=0\n",
    "#     for edge_1,edge_2 in zip(bin_edges[:-1],bin_edges[1:]):\n",
    "#         if (value>edge_1)&(value<=edge_2):\n",
    "#             loc_bin = i\n",
    "#         else:\n",
    "#             i+=1\n",
    "#             continue\n",
    "\n",
    "#     if value<=bin_edges[0]:\n",
    "#         loc_bin = 0\n",
    "\n",
    "#     if value>=bin_edges[-1]:\n",
    "#         loc_bin = len(bin_edges)-2\n",
    "\n",
    "#     return(loc_bin)\n",
    "\n",
    "# def model_location(model_dict,location_details,evidence_dict,variable_list):\n",
    "    \n",
    "#     '''\n",
    "#     function for adding the location information for one side model to the evidence dictionary\n",
    "#     '''\n",
    "    \n",
    "#     for variable in variable_list:\n",
    "\n",
    "#         bin_edges = model_dict['variables'][variable]['bin_edges'][0]\n",
    "#         value = location_details[variable]\n",
    "\n",
    "#         var_bin = bin_locator(value,bin_edges)\n",
    "        \n",
    "#         evidence_array = [0]*(len(bin_edges)-1)\n",
    "#         evidence_array[var_bin] = 1\n",
    "        \n",
    "#         evidence_dict.update({\n",
    "#             variable:evidence_array\n",
    "#         })\n",
    "\n",
    "#     # Add evidence to model dict\n",
    "#     model_location_dict = BNModel().add_evidence_to_dict(model_dict,evidence_dict)\n",
    "    \n",
    "#     # Set evidence and get beliefs\n",
    "#     model_location_dict = BNModel().update_evidence(model_location_dict)\n",
    "    \n",
    "#     return(model_location_dict)\n",
    "\n",
    "# def location_probabilities(evidence_dict,model_dict,variable_list,df_profiles):\n",
    "#     '''\n",
    "    \n",
    "#     Function for setting evidence and determing probabilties for twl at each point around the island based \n",
    "#     on the reef characteristics at each location\n",
    "    \n",
    "#     '''\n",
    "    \n",
    "#     location_probabilities_dict = {}\n",
    "# #     figure_dict = {}\n",
    "    \n",
    "#     for index,row in df_profiles.iterrows():\n",
    "\n",
    "#         model_location_dict = model_location(model_dict,row,evidence_dict,variable_list)\n",
    "#         location_probabilities = model_location_dict['variables']['TWL']['resulting_probs'][0]\n",
    "\n",
    "#         df_location_probabilities = pd.DataFrame.from_dict(location_probabilities,orient='index')\n",
    "        \n",
    "# #         # Create figure for popup\n",
    "# #         fig = plt.figure(figsize=(2,2))\n",
    "# #         plt.bar(x=df_location_probabilities.index,height=df_location_probabilities[0])\n",
    "# #         plt.savefig('{}_{}.png'.format(int(row.reef_long*1000),int(row.reef_lat*1000)))\n",
    "# #         plt.close()\n",
    "        \n",
    "#         largest_cat = df_location_probabilities.idxmax()[0]\n",
    "\n",
    "#         location_probabilities_dict.update({\n",
    "#             (row.reef_long,row.reef_lat):\\\n",
    "#                 model_dict['variables']['TWL']['discretisation']['bin_names'].index(largest_cat)\n",
    "#         })\n",
    "        \n",
    "# #         figure_dict.update({\n",
    "# #             (row.reef_long,row.reef_lat):fig#html_graph\n",
    "# #         })\n",
    "        \n",
    "#     return(location_probabilities_dict)\n",
    "\n",
    "# def data2geojson(df):\n",
    "#     features = []\n",
    "#     insert_features = lambda X: features.append(\n",
    "#             geojson.Feature(geometry=geojson.Point((X[\"long\"],\n",
    "#                                                     X[\"lat\"])),\n",
    "#                             properties=dict(name=X[\"most_likely_twl\"])))\n",
    "#     df.apply(insert_features, axis=1)\n",
    "        \n",
    "#     return(geojson.FeatureCollection(features))\n",
    "\n",
    "# # Load SLR Projections\n",
    "# data_location = \"/src/Dataset/D7_MSL_projections/\"\n",
    "# file_name = \"distributions_dict\"\n",
    "# with open(\"{}{}.json\".format(data_location,file_name), 'r') as fp:\n",
    "#     SL_proj_dict = json.load(fp)\n",
    "    \n",
    "# def SLR_proj_extractor(SL_proj_dict,AIS_config,rcp,year):\n",
    "#     '''\n",
    "#     Function for getting SLR projections for a given Antarctic icesheet, rcp and year\n",
    "#     Years start as 2020 and go up in lots of 10 until 2150 (2100 for dp16)\n",
    "#     '''\n",
    "#     SLR_prob_dict = SL_proj_dict[\"('{}', '{}', {})\".format(AIS_config,rcp,year)]\n",
    "#     SLR_median_prob = np.max([float(x) for x in list(SLR_prob_dict.keys())])\n",
    "#     SLR_median_MSL = float(SLR_prob_dict[str(SLR_median_prob)])/1000 #units is m\n",
    "\n",
    "#     return(SLR_median_MSL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_figure(\n",
    "#     view,tide_bin,wave_height_bin,wave_period_bin,wave_direction_bin,wind_u_bin,wind_v_bin,proj_time,time\n",
    "#     ):\n",
    "#     # Extract the right model from the dictionary of model\n",
    "#     lagoon_model_dict = model_dicts_through_time_dict[time]['lagoon']\n",
    "#     ocean_model_dict = model_dicts_through_time_dict[time]['ocean']\n",
    "    \n",
    "#     ########### get the MSL bin based on slider value\n",
    "#     msl_proj = SLR_proj_extractor(SL_proj_dict,'k14','26','{}'.format(proj_time))\n",
    "# #     ocean_model_dict['variables']['MSL']['bin_edges'][0]\n",
    "#     bin_count = bin_locator(msl_proj,ocean_model_dict['variables']['MSL']['bin_edges'][0])\n",
    "#     msl_bin = ocean_model_dict['variables']['MSL']['discretisation']['bin_names'][bin_count]\n",
    "    \n",
    "#     if view == 'Map':\n",
    "#         map_osm = folium.Map(location=[1.448888, 172.991794],zoom_start=11)\n",
    "#     elif view == 'Satellite':\n",
    "#         token = \"pk.eyJ1Ijoic2hhbm5vbi1iZW5ndHNvbiIsImEiOiJja3F1Y2Q0dHEwMzYwMm9wYmtzYzk2bDZuIn0.5jGMyEiJdmXs1HL7x3ThPw\" # your mapbox token\n",
    "#         tileurl = 'https://api.mapbox.com/v4/mapbox.satellite/{z}/{x}/{y}@2x.png?access_token=' + str(token)\n",
    "\n",
    "#         map_osm = folium.Map(location=[1.448888, 172.991794], zoom_start=11, tiles=tileurl, attr='Mapbox')\n",
    "        \n",
    "#     twl_bin_edges = [round(x,2) for x in ocean_model_dict['variables']['TWL']['bin_edges'][0]]\n",
    "#     twl_bins = ocean_model_dict['variables']['TWL']['discretisation']['bin_names']\n",
    "\n",
    "#     colours_rgb = matplotlib.pyplot.get_cmap('seismic')(np.arange(0,1+1/len(twl_bins),1/(len(twl_bins)-1)))\n",
    "#     colour_hex_dict = {i:rgb2hex(int(255*colours_rgb[i][0]),int(255*colours_rgb[i][1]),int(255*(colours_rgb[i][2]))) for i in np.arange(0,len(twl_bins),1)}\n",
    "    \n",
    "#     ################################################\n",
    "    \n",
    "#     # Create an empty dictionary for the evidence and populate as you go\n",
    "#     ocean_evidence_dict = {}\n",
    "    \n",
    "#     for var_bin,var_name in zip([tide_bin,msl_bin,wave_height_bin,wave_period_bin,wave_direction_bin],\n",
    "#                                 ['Tide','MSL','Hs_offshore','Tm_offshore','Dir_offshore']):\n",
    "\n",
    "#         ## Set in the evidence dict to be as indicated in the dropdown\n",
    "#         bin_index = ocean_model_dict['variables'][var_name]['discretisation']['bin_names'].index(var_bin)\n",
    "#         # Create a list of the tide evidence (all zero except as indicated by dropdown. Dropdown=1)\n",
    "#         evidence = [0 for x in ocean_model_dict['variables'][var_name]['discretisation']['bin_names']]\n",
    "#         evidence[bin_index] = 1\n",
    "#         ocean_evidence_dict.update({\n",
    "#             var_name:evidence\n",
    "#         })\n",
    "    \n",
    "#     # Create a list of variables that are location specific to set as evidence in the network\n",
    "#     variable_list = ['reef_width','reef_depth','forereef_slope','shore_dir']\n",
    "    \n",
    "#     # get the probability dictionary\n",
    "#     location_probabilities_dict = location_probabilities(ocean_evidence_dict,ocean_model_dict,variable_list,df_ocean_profiles)\n",
    "    \n",
    "#     # Create dataframe to plot\n",
    "#     df_twl_locations = pd.DataFrame.from_dict(location_probabilities_dict,orient='index').rename(columns={0:'most_likely_twl'})\n",
    "#     df_twl_locations['long'] = [long for long,lat in df_twl_locations.index]\n",
    "#     df_twl_locations['lat'] = [lat for long,lat in df_twl_locations.index]\n",
    "#     df_twl_locations.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "#     data_ocean = data2geojson(df_twl_locations)\n",
    "    \n",
    "#     colors_hex_points_ocean = [colour_hex_dict[x] for x in df_twl_locations.most_likely_twl]\n",
    "    \n",
    "#     #####################################################################\n",
    "    \n",
    "#     # Create an empty dictionary for the evidence and populate as you go\n",
    "#     lagoon_evidence_dict = {}\n",
    "    \n",
    "#     for var_bin,var_name in zip([tide_bin,msl_bin,wave_height_bin,wave_period_bin,wave_direction_bin,wind_u_bin,wind_v_bin],\n",
    "#                                 ['Tide','MSL','Hs_offshore','Tm_offshore','Dir_offshore','wind_u','wind_v']):\n",
    "\n",
    "#         ## Set in the evidence dict to be as indicated in the dropdown\n",
    "#         bin_index = lagoon_model_dict['variables'][var_name]['discretisation']['bin_names'].index(var_bin)\n",
    "#         # Create a list of the tide evidence (all zero except as indicated by dropdown. Dropdown=1)\n",
    "#         evidence = [0 for x in lagoon_model_dict['variables'][var_name]['discretisation']['bin_names']]\n",
    "#         evidence[bin_index] = 1\n",
    "#         lagoon_evidence_dict.update({\n",
    "#             var_name:evidence\n",
    "#         })\n",
    "    \n",
    "#     # Create a list of variables that are location specific to set as evidence in the network\n",
    "#     variable_list = []\n",
    "    \n",
    "#     # get the probability dictionary\n",
    "#     location_probabilities_dict = location_probabilities(lagoon_evidence_dict,lagoon_model_dict,variable_list,df_lagoon_profiles)\n",
    "    \n",
    "#     # Create dataframe to plot\n",
    "#     df_twl_locations = pd.DataFrame.from_dict(location_probabilities_dict,orient='index').rename(columns={0:'most_likely_twl'})\n",
    "#     df_twl_locations['long'] = [long for long,lat in df_twl_locations.index]\n",
    "#     df_twl_locations['lat'] = [lat for long,lat in df_twl_locations.index]\n",
    "#     df_twl_locations.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "#     data_lagoon = data2geojson(df_twl_locations)\n",
    "    \n",
    "#     colors_hex_points_lagoon = [colour_hex_dict[x] for x in df_twl_locations.most_likely_twl]\n",
    "    \n",
    "#     #####################################################################\n",
    "    \n",
    "#     features_list = data_ocean['features']+data_lagoon['features']\n",
    "    \n",
    "#     data = data_ocean\n",
    "#     data.update({\n",
    "#         'features':features_list\n",
    "#     })\n",
    "    \n",
    "#     colors_hex_points = colors_hex_points_ocean+colors_hex_points_lagoon\n",
    "    \n",
    "#     #####################################################################\n",
    "\n",
    "#     for feature,color in zip(features_list,colors_hex_points):\n",
    "#         feature['properties'] = {'color':color,'weight':1,'markerColor':color,'fillOpacity':1,'fillColor':color}\n",
    "#         long,lat = feature['geometry']['coordinates']\n",
    "        \n",
    "#         marker = folium.CircleMarker([lat,long],color=color,\n",
    "#                                     # popup='<img src={}_{}.png>'.format(int(long*1000),int(lat*1000)),\n",
    "#                                    fill_color=color,fill=True,fill_opacity='1',radius=5)\n",
    "#         marker.add_to(map_osm)\n",
    "        \n",
    "#     twl_bin_edge_labels = ['{} to {} m'.format(\n",
    "#         x,y) for x,y in zip(twl_bin_edges[:-1],twl_bin_edges[1:])]\n",
    "        \n",
    "#     output_list = []\n",
    "#     for rgb_color in colours_rgb:\n",
    "#         output = plt.scatter([],[],color=rgb_color)\n",
    "#         output_list.append(output)\n",
    "        \n",
    "#     legend = plt.legend(output_list,twl_bin_edge_labels,title='Total water level anomaly',fontsize=10)\n",
    "#     plt.setp(legend.get_title(),fontsize=12)\n",
    "    \n",
    "#     plt.axis('off')\n",
    "#     plt.savefig('legend.png')\n",
    "    \n",
    "#     plt.close()\n",
    "    \n",
    "#     url = (\n",
    "#         \"legend.png\"\n",
    "#     )    \n",
    "    \n",
    "#     FloatImage(url, bottom=55, left=55).add_to(map_osm)\n",
    "    \n",
    "#     map_osm.save('test.html')\n",
    "        \n",
    "#     return(map_osm)\n",
    "\n",
    "# # compile the figure\n",
    "# lagoon_model_dict,ocean_model_dict = initialise_model_dictionaries()\n",
    "# tide_bins = ocean_model_dict['variables']['Tide']['discretisation']['bin_names']\n",
    "# wave_height_bins = ocean_model_dict['variables']['Hs_offshore']['discretisation']['bin_names']\n",
    "# wave_period_bin = ocean_model_dict['variables']['Tm_offshore']['discretisation']['bin_names']\n",
    "# wave_direction_bin = ocean_model_dict['variables']['Dir_offshore']['discretisation']['bin_names']\n",
    "# wind_u_bin = lagoon_model_dict['variables']['wind_u']['discretisation']['bin_names']\n",
    "# wind_v_bin = lagoon_model_dict['variables']['wind_u']['discretisation']['bin_names']\n",
    "# time = list(model_dicts_through_time_dict.keys())  \n",
    "\n",
    "# # Create the plot with the widget\n",
    "# map_osm = interact_manual(test_figure,\n",
    "#                 view = widgets.Dropdown(options=['Map','Satellite'],value='Map',description='View type',disabled=False),\n",
    "#                 tide_bin = widgets.Dropdown(options=tide_bins,value='Mid',description='Tide',disabled=False),\n",
    "#                 wave_height_bin = widgets.Dropdown(options=wave_height_bins,value='Mid',description='Wave height',disabled=False),\n",
    "#                 wave_period_bin = widgets.Dropdown(options=wave_period_bin,value='Mid',description='Wave period',disabled=False),\n",
    "#                 wave_direction_bin = widgets.Dropdown(options=wave_direction_bin,value='NNE',description='Wave direction',disabled=False),\n",
    "#                 wind_u_bin = widgets.Dropdown(options=wind_u_bin,value='Mid',description='Wind u',disabled=False),\n",
    "#                 wind_v_bin = widgets.Dropdown(options=wind_v_bin,value='Mid',description='Wind v',disabled=False),\n",
    "#                 proj_time = widgets.IntSlider(min=2020,max=2150,step=10,value=2020,description='SLR prediction'),\n",
    "#                 time = widgets.Dropdown(options=time,value=727930.0,description='Time',disabled=False)\n",
    "#                )\n",
    "\n",
    "# map_osm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "cite2c": {
   "citations": {
    "2344856/V5HIVSEQ": {
     "DOI": "10.1017/S0263593300020782",
     "URL": "https://www.cambridge.org/core/journals/earth-and-environmental-science-transactions-of-royal-society-of-edinburgh/article/an-alternative-astronomical-calibration-of-the-lower-pleistocene-timescale-based-on-odp-site-677/D02E93BFBF418256AD00642C8A98277C",
     "abstract": "Ocean Drilling Program (ODP) Site 677 provided excellent material for high resolution stable isotope analysis of both benthonic and planktonic foraminifera through the entire Pleistocene and upper Pliocene. The oxygen isotope record is readily correlated with the SPECMAP stack (Imbrie et al. 1984) and with the record from DSDP 607 (Ruddiman et al. 1986) but a significantly better match with orbital models is obtained by departing from the timescale proposed by these authors below Stage 16 (620 000 years). It is the stronger contribution from the precession signal in the record from ODP Site 677 that provides the basis for the revised timescale. Our proposed modification to the timescale would imply that the currently adopted radiometric dates for the Matuyama–Brunhes boundary, the Jaramillo and Olduvai Subchrons and the Gauss–Matuyama boundary underestimate their true astronomical ages by between 5 and 7%.",
     "accessed": {
      "day": 19,
      "month": 5,
      "year": 2020
     },
     "author": [
      {
       "family": "Shackleton",
       "given": "N. J."
      },
      {
       "family": "Berger",
       "given": "A."
      },
      {
       "family": "Peltier",
       "given": "W. R."
      }
     ],
     "container-title": "Earth and Environmental Science Transactions of The Royal Society of Edinburgh",
     "id": "2344856/V5HIVSEQ",
     "issue": "4",
     "issued": {
      "year": 1990
     },
     "language": "en",
     "note": "citation key: shackleton1990alternative",
     "page": "251-261",
     "page-first": "251",
     "title": "An alternative astronomical calibration of the lower Pleistocene timescale based on ODP Site 677",
     "type": "article-journal",
     "volume": "81"
    }
   }
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "238px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "744px",
    "left": "1596px",
    "right": "20px",
    "top": "131px",
    "width": "279px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
